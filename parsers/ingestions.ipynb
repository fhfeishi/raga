{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376502f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model \n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embedding = HuggingFaceEmbedding(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    device=\"cpu\",                 # 建议放顶层\n",
    "    cache_folder=r\"E:\\local_models\\huggingface\\cache\\hub\",\n",
    "    trust_remote_code=True,       # 建议放顶层\n",
    "    model_kwargs={\"local_files_only\": True},   # 允许联网 False\n",
    ")\n",
    "Settings.embed_model = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4281fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm\n",
    "\n",
    "# local huggingface llm \n",
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM \n",
    "from llama_index.core import Settings \n",
    "\n",
    "local_llm = HuggingFaceLLM(\n",
    "    model_name=model_name,\n",
    "    tokenizer_name=model_name,\n",
    "    context_window=1400,\n",
    "    max_new_tokens=300,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95},\n",
    "    device_map='cpu'\n",
    ")\n",
    "\n",
    "# chat model  api-key \n",
    "# openai  pypi    \n",
    "\n",
    "from openai import OpenAI \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "DEEPSEEK_API_KEY = os.getenv(\"GLM_API_KEY\")   # https://api.deepseek.com\n",
    "QWEN_API_KEY = os.getenv(\"GLM_API_KEY\")       # https://dashscope.aliyuncs.com/compatible-mode/v1\n",
    "\n",
    "# client\n",
    "client = OpenAI(\n",
    "    api_key=QWEN_API_KEY,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f74f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "纯文本长度： 5831\n",
      "figs.json 键： ['im_abs', 'ims_desc', 'ims_absp', 'ims_bs64', 'ims_annos']\n",
      "ims_desc 示例： [('1', '本实用新型整体结构示意图'), ('2', '本实用新型剖视图'), ('3', '本实用新型爆炸视图')]\n",
      "ims_absp 示例： [('1', '本实用新型整体结构示意图'), ('2', '本实用新型剖视图'), ('3', '本实用新型爆炸视图')]\n",
      "ims_annos 示例： ['附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域']\n"
     ]
    }
   ],
   "source": [
    "# load data  metadata \n",
    "\n",
    "from pathlib import Path \n",
    "import json \n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "from llama_index.core import Document, SimpleDirectoryReader, VectorStoreIndex, StorageContext, load_index_from_storage \n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryResult\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.extractors import TitleExtractor     # 需要接入llm\n",
    "\n",
    "# text-info: full_split_struct.md (可能还不是很干净，有一些零散的干扰信息语句，影响不大)  --后续需要优化\n",
    "# figs-info: figs.json 就是结构化的图像信息\n",
    "data_root = Path.cwd().parent / \".log/SimplePDF\"\n",
    "assert Path(data_root).is_dir()\n",
    "mdfs: Path = next(Path(data_root).rglob('full_split_struct.md'), None)\n",
    "assert  Path(mdfs).exists()\n",
    "figs: Path = Path(mdfs).with_name(\"figs.json\")\n",
    "assert figs.is_file()\n",
    "\n",
    "\"\"\"  figs.json\n",
    "{\n",
    "  \"im_abs\": [\n",
    "    \"path/to/im_abs\",\n",
    "    \"\"\n",
    "    ],\n",
    "  \"ims_desc\": {\n",
    "    \"1\": \"本实用新型整体结构示意图\",\n",
    "    ...\n",
    "  },\n",
    "  \"ims_absp\": {\n",
    "    \"1\": \"path/to/im_1\",\n",
    "    ...\n",
    "  },\n",
    "  \"ims_bs64\": {\n",
    "      \"1\": \"bs64xx\",\n",
    "      ...\n",
    "  },\n",
    "  \"ims_annos\": \"附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，...\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# load text_  figs_\n",
    "def load_md_and_figs(md_path: Path, figs_name: str = \"figs.json\") -> Tuple[str, Dict[str, Any]]:\n",
    "    \"\"\"读取单篇专利的 md 文本+figs.json（若缺失则空字典）\"\"\"\n",
    "    text = md_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    fj = md_path.with_name(figs_name)\n",
    "    figs: Dict = {}\n",
    "    if fj.exists():\n",
    "        with open(fj, \"r\", encoding=\"utf-8\") as f:\n",
    "            figs = json.load(f)\n",
    "    return text, figs\n",
    "text_, figs_ = load_md_and_figs(md_path=mdfs)\n",
    "\n",
    "print(\"纯文本长度：\", len(text_))\n",
    "print(\"figs.json 键：\", list(figs_.keys()))\n",
    "print(\"ims_desc 示例：\", list((figs_.get(\"ims_desc\") or {}).items())[:3])\n",
    "print(\"ims_absp 示例：\", list((figs_.get(\"ims_desc\") or {}).items())[:3])\n",
    "print(\"ims_annos 示例：\", [(figs_.get(\"ims_annos\") or \"\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5335e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node\n",
    "\n",
    "import uuid\n",
    "\n",
    "# Vector stores\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore  # faiss\n",
    "from llama_index.core.vector_stores import SimpleVectorStore  # 内存\n",
    "\n",
    "# Optional BM25\n",
    "from llama_index.retrievers.bm25 import BM25Retriever  # use or not\n",
    "\n",
    "from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n",
    "\"\"\"  TextNode\n",
    "\n",
    "class MetadataMode(str, Enum):\n",
    "    ALL = \"all\"\n",
    "    EMBED = \"embed\"\n",
    "    LLM = \"llm\"\n",
    "    NONE = \"none\"\n",
    "\n",
    "class TextNode(BaseNode):\n",
    "    text:   for embedding\n",
    "    metadata: for embedding \n",
    "    \n",
    "    get_content(metadata_mode: MetadataMode)\n",
    "        - 先根据 mode 通过 get_metadata_str(mode) 生成元数据串\n",
    "        - 如果 mode != NONE 且有元数据，就用 text_template 把 content（= self.text）和 metadata_str 拼起来返回；否则直接返回 self.text。\n",
    "\n",
    "    get_text() == get_content(metadata_mode=MetadataMode.NONE)\n",
    "    get_metadata_str(mode) : ALL, NONE, LLM, EMBED\n",
    "\n",
    "    text_template: 控制当需要把元数据拼到正文里时的格式（默认是“content + metadata_str”）。\n",
    "    hash: 基于 text + metadata 计算；用于去重等（不是节点 ID）。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _to_ascii_digits(s: str) -> str:\n",
    "    _DIGIT_TRANS = str.maketrans(\"０１２３４５６７８９\", \"0123456789\")\n",
    "    return (s or \"\").translate(_DIGIT_TRANS)\n",
    "\n",
    "# nodes\n",
    "# chunk_size=700, chunk_overlap=128  # 著录信息是最重要的一段  对应于pdf的第一页， markdown的第一部分\n",
    "def build_text_nodes_from_markdown(text: str, doc_id: str, \n",
    "                                   chunk_size: int=700, \n",
    "                                   chunk_overlap: int=128) -> List[TextNode]:\n",
    "    splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = splitter.split_text(text)\n",
    "    nodes: List[TextNode] = []\n",
    "    for i, ch in enumerate(chunks, 1):\n",
    "        nodes.append(TextNode(\n",
    "            text=ch,\n",
    "            id_=f\"{doc_id}::text::{i}\",\n",
    "            metadata={\"doc_id\": doc_id, \"node_type\": \"text\", \"chunk_idx\": i},\n",
    "        ))\n",
    "    return nodes\n",
    "\n",
    "def build_figure_nodes_from_figs(figs: Dict[str, Any], doc_id: str) -> List[TextNode]:\n",
    "    nodes: List[TextNode] = []\n",
    "    # key: value\n",
    "    ims_desc: Dict[str, str] = figs.get(\"ims_desc\", {}) or {}\n",
    "    ims_absp: Dict[str, str] = figs.get(\"ims_absp\", {}) or {}\n",
    "    ims_bs64: Dict[str, str] = figs.get(\"ims_bs64\", {}) or {}\n",
    "    annos: str = (figs.get(\"ims_annos\") or \"\").strip()\n",
    "\n",
    "    # 摘要图\n",
    "    im_abs = figs.get(\"im_abs\") or []\n",
    "    if isinstance(im_abs, list) and len(im_abs) >= 1:\n",
    "        abs_path = im_abs[0] if isinstance(im_abs[0], str) else \"\"\n",
    "        # text_for_embed = \"摘要图\" + (f\"；附图标记：{annos}\" if annos else \"\")    # TextNode(text=...) 的 text 字段就是喂给 embedding 模型用于建库/检索的内容。\n",
    "        text_for_embed = \"摘要\" \n",
    "        nodes.append(TextNode(\n",
    "            text=text_for_embed,\n",
    "            id_=f\"{doc_id}::fig::abs\",\n",
    "            metadata = {\"doc_id\": doc_id, \n",
    "                        \"node_type\": \"figure\",\n",
    "                        \"fig_no\": \"abs\",\n",
    "                        \"fig_desc\": \"摘要图\",\n",
    "                        \"fig_path\": abs_path,\n",
    "                        \"fig_b64\": \"B64(omitted)\" if im_abs[1:] else \"\",\n",
    "                        \"fig_annos\": annos,\n",
    "                        \"display_text\": \"【摘要图】\",   # 前端用\n",
    "                        },\n",
    "            excluded_embed_metadata_keys = [\"fig_path\", \"fig_b64\", \"fig_annos\", \"display_text\"],     # 不参与embedding的metadata字段\n",
    "            excluded_llm_metadata_keys = [\"fig_b64\"],       # 不参与llm生成的metadata字段\n",
    "        ))\n",
    "\n",
    "    # 普通图\n",
    "    def _key_sorter(k: str) -> int:\n",
    "        try: return int(_to_ascii_digits(k))\n",
    "        except: return 10**9\n",
    "\n",
    "    for k in sorted(ims_desc.keys(), key=_key_sorter):\n",
    "        desc = (ims_desc.get(k) or \"\").strip()\n",
    "        pth  = (ims_absp.get(k) or \"\").strip()\n",
    "        # text_for_embed = f\"图{k}：{desc}\" + (f\"；附图标记：{annos}\" if annos else \"\")\n",
    "        text_for_embed = f\"图{k}为{desc}\" \n",
    "        nodes.append(TextNode(\n",
    "            text=text_for_embed,       #  text + metadata -> embed\n",
    "            id_=f\"{doc_id}::fig::{k}\",\n",
    "            metadata={\n",
    "                \"doc_id\": doc_id, \n",
    "                \"node_type\": \"figure\",\n",
    "                \"fig_no\": k, \n",
    "                \"fig_desc\": desc,\n",
    "                \"fig_path\": pth, \n",
    "                \"fig_b64\": \"B64(omitted)\" if (ims_bs64.get(k) or \"\") else \"\",\n",
    "                # \"fig_annos\": annos,  \n",
    "                \"display_text\":f\"【图{k} {desc}】\",   # 前端用  \n",
    "            },\n",
    "            excluded_embed_metadata_keys = [\"fig_path\", \"fig_b64\", \"fig_annos\", \"display_text\"],     # 不参与embedding的metadata字段\n",
    "            excluded_llm_metadata_keys = [\"fig_b64\"],       # 不参与llm生成的metadata字段\n",
    "        ))\n",
    "    return nodes\n",
    "\n",
    "\n",
    "# 小测试：构建一份示例的节点数量\n",
    "doc_id_demo = str(uuid.uuid5(uuid.NAMESPACE_URL, str(mdfs.resolve())))\n",
    "test_nodes = build_text_nodes_from_markdown(text_, doc_id_demo) + build_figure_nodes_from_figs(figs_, doc_id_demo)\n",
    "len(test_nodes), sum(1 for n in test_nodes if n.metadata[\"node_type\"]==\"figure\")\n",
    "\n",
    "\n",
    "def _exclude_metadata_for_embedding(node: TextNode, extra_keys: List[str] = None):\n",
    "    \"\"\"确保这些 metadata 不会被拼进 EMBED 文本。\"\"\"\n",
    "    extra_keys = extra_keys or []\n",
    "    # 复制成 set，再并集（有些实现里是 tuple）\n",
    "    exc = set(getattr(node, \"excluded_embed_metadata_keys\", []))\n",
    "    exc |= {\"fig_annos\", \"fig_b64\", \"fig_path\"} | set(extra_keys)\n",
    "    node.excluded_embed_metadata_keys = list(exc)\n",
    "\n",
    "def _exclude_metadata_for_llm(node: TextNode, extra_keys: List[str] = None):\n",
    "    \"\"\"如果你也不想把这些 metadata 在 get_content(LLM) 里拼给 LLM，可一并排除。\"\"\"\n",
    "    extra_keys = extra_keys or []\n",
    "    exc = set(getattr(node, \"excluded_llm_metadata_keys\", []))\n",
    "    exc |= {\"fig_b64\"} | set(extra_keys)\n",
    "    node.excluded_llm_metadata_keys = list(exc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e0016ac3684540b26a3fafda65e15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[build] 新建索引：nodes=19\n"
     ]
    }
   ],
   "source": [
    "# index\n",
    "from typing import Optional\n",
    "import faiss\n",
    "\n",
    "# Settings.embed_model \n",
    "Settings.llm = None\n",
    "\n",
    "persist_dir = Path.cwd().parent / \".log/faiss_db\"\n",
    "persist_dir.mkdir(parents=True, exist_ok=True)\n",
    "faiss_index_path = persist_dir / \"faiss.index\"\n",
    "meta_path = persist_dir / \"vector_meta.json\"\n",
    "\n",
    "def _storage_triplet_ok(pdir: Path) -> bool:\n",
    "    return all([\n",
    "        (pdir / \"docstore.json\").exists(),\n",
    "        (pdir / \"index_store.json\").exists(),\n",
    "        (pdir / \"faiss.index\").exists(),\n",
    "    ])\n",
    "    \n",
    "# ---------- helper: 读/写 meta ----------\n",
    "def _read_meta(p: Path) -> Dict[str, Any]:\n",
    "    if not p.exists():\n",
    "        return {}\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _write_meta(p: Path, meta: Dict[str, Any]) -> None:\n",
    "    with open(p, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "\n",
    "# ---------- helper: 推断 embedding 维度（如果你没手动填） ----------\n",
    "def infer_embed_dim(default_dim: Optional[int] = None) -> int:\n",
    "    if default_dim and default_dim > 0:\n",
    "        return default_dim\n",
    "    # 尝试从 Settings.embed_model 推断\n",
    "    em = Settings.embed_model\n",
    "    if em is None:\n",
    "        raise ValueError(\"Settings.embed_model 未设置，且未显式指定 embedding 维度。\")\n",
    "    try:\n",
    "        # 大多数本地 embedding 都支持 get_text_embedding\n",
    "        vec = em.get_text_embedding(\"probe-dim\")\n",
    "        return len(vec)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"无法从 Settings.embed_model 推断维度，请手动传入 embedding_vector_length。错误：{e}\")\n",
    "\n",
    "# ---------- helper: 校验 FAISS 维度 ----------\n",
    "def _faiss_dim(path: Path) -> Optional[int]:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    try:\n",
    "        idx = faiss.read_index(str(path))\n",
    "        return idx.d\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------- helper: 需要重建吗？（根据 meta + 文件 + 维度） ----------\n",
    "def need_rebuild(\n",
    "    pdir: Path,\n",
    "    current_cfg: Dict[str, Any],\n",
    "    faiss_path: Path,\n",
    ") -> bool:\n",
    "    # 文件不全 -> 必须重建\n",
    "    if not _storage_triplet_ok(pdir):\n",
    "        return True\n",
    "\n",
    "    # 维度不一致 -> 必须重建\n",
    "    cur_faiss_d = _faiss_dim(faiss_path)\n",
    "    if not cur_faiss_d:\n",
    "        return True\n",
    "    if cur_faiss_d != int(current_cfg.get(\"embed_dim\", -1)):\n",
    "        return True\n",
    "\n",
    "    # meta 不一致 -> 必须重建\n",
    "    old = _read_meta(meta_path)\n",
    "    # 只比较关键键，避免时间戳等非关键项影响\n",
    "    keys_to_compare = [\"embed_model\", \"embed_dim\", \"chunk_size\", \"chunk_overlap\"]\n",
    "    for k in keys_to_compare:\n",
    "        if old.get(k) != current_cfg.get(k):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# ---------- helper: 清理旧持久化 ----------\n",
    "def nuke_persist_dir(pdir: Path) -> None:\n",
    "    # 只删我们知道的文件，避免误删你目录里其他东西\n",
    "    for fn in [\"docstore.json\", \"index_store.json\", \"vector_store.json\", \"faiss.index\", \"vector_meta.json\"]:\n",
    "        f = pdir / fn\n",
    "        if f.exists():\n",
    "            f.unlink()\n",
    "\n",
    "\n",
    "def build_or_load_index(md_files: List[Path], embedding_vector_length: int=1024) -> Tuple[VectorStoreIndex, List[TextNode]]:\n",
    "    \n",
    "    # init \n",
    "    vector_store = FaissVectorStore(faiss_index=faiss.IndexFlatL2(embedding_vector_length))\n",
    "    # vector_store = SimpleVectorStore()  # 内存\n",
    "\n",
    "    # -- 重建\n",
    "    # # 若已存在存储，直接加载（加快重跑）\n",
    "    if _storage_triplet_ok(persist_dir):\n",
    "        storage_context = StorageContext.from_defaults(\n",
    "            persist_dir=persist_dir,\n",
    "            vector_store=vector_store\n",
    "            )\n",
    "        index = load_index_from_storage(storage_context)\n",
    "        \n",
    "        # 为了 BM25 或其他用途，再次扫描构建 nodes（不影响向量库）\n",
    "        nodes_cache: List[TextNode] = []\n",
    "        for md in md_files:\n",
    "            text, figs = load_md_and_figs(md)\n",
    "            doc_id = str(uuid.uuid5(uuid.NAMESPACE_URL, str(md.resolve())))\n",
    "            nodes_cache += build_text_nodes_from_markdown(text, doc_id)\n",
    "            nodes_cache += build_figure_nodes_from_figs(figs, doc_id)\n",
    "        print(f\"[load] 载入索引，缓存 nodes={len(nodes_cache)}\")\n",
    "        return index, nodes_cache\n",
    "\n",
    "    # 首建：扫描数据 -> nodes\n",
    "    all_nodes: List[TextNode] = []\n",
    "    \n",
    "    for md in md_files:\n",
    "        text, figs = load_md_and_figs(md)\n",
    "        doc_id = str(uuid.uuid5(uuid.NAMESPACE_URL, str(md.resolve())))\n",
    "        all_nodes += build_text_nodes_from_markdown(text, doc_id)\n",
    "        all_nodes += build_figure_nodes_from_figs(figs, doc_id)\n",
    "\n",
    "    # 构建 faiss_db   \n",
    "    # ## 参数persist_dir只有在加载的时候用，这里是创建 \n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store) \n",
    "    index = VectorStoreIndex(all_nodes, storage_context=storage_context, show_progress=True)\n",
    "    \n",
    "    storage_context.persist(persist_dir=str(persist_dir))\n",
    "    print(f\"[build] 新建索引：nodes={len(all_nodes)}\")\n",
    "    return index, all_nodes\n",
    "\n",
    "index, nodes_cache = build_or_load_index(md_files=[mdfs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f0a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever \n",
    "\n",
    "# ==== ① 向量检索参数 & 展示工具 ====\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple, Iterable\n",
    "\n",
    "from llama_index.core import QueryBundle, VectorStoreIndex\n",
    "from llama_index.core.schema import TextNode, NodeWithScore\n",
    "\n",
    "# ------- 全局/默认参数（可自由改） -------\n",
    "TOP_K = 8\n",
    "VECTOR_MODE = \"mmr\"   # \"default\" | \"mmr\"\n",
    "MMR_ALPHA = 0.5       # 仅当 VECTOR_MODE=\"mmr\" 生效，越大越多样化\n",
    "USE_BM25 = True       # 你也可在调用时覆盖\n",
    "HYBRID_W_VEC = 0.70   # 混合检索加权：向量\n",
    "HYBRID_W_BM25 = 0.30  # 混合检索加权：BM25\n",
    "PREFER_FIG_BOOST = 0.02  # 检索命中“图N”时，小幅提升对应 figure 的分数\n",
    "TEXT_PREVIEW_CHARS = 200 # 打印预览字数\n",
    "\n",
    "FIG_PAT = re.compile(r\"图\\s*([0-9０-９]+)\")\n",
    "_DIGIT_TRANS = str.maketrans(\"０１２３４５６７８９\", \"0123456789\")\n",
    "\n",
    "def _to_ascii_int(s: str) -> Optional[int]:\n",
    "    try:\n",
    "        return int(s.translate(_DIGIT_TRANS))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _fig_nums_in_text(s: str) -> List[int]:\n",
    "    out = []\n",
    "    for m in FIG_PAT.finditer(s or \"\"):\n",
    "        n = _to_ascii_int(m.group(1))\n",
    "        if n is not None:\n",
    "            out.append(n)\n",
    "    return out\n",
    "\n",
    "def _has_fig_mention(q: str) -> List[int]:\n",
    "    return _fig_nums_in_text(q or \"\")\n",
    "\n",
    "# ------- 统一结果结构 -------\n",
    "@dataclass\n",
    "class HitRow:\n",
    "    node_id: str\n",
    "    node_type: str\n",
    "    score: float\n",
    "    text_preview: str\n",
    "    # figure extra (如果是配图)\n",
    "    fig_no: Optional[str] = None\n",
    "    fig_desc: Optional[str] = None\n",
    "    fig_path: Optional[str] = None\n",
    "    fig_annos: Optional[str] = None\n",
    "\n",
    "def _coerce_hits(hits: Iterable[Any]) -> List[Tuple[TextNode, float]]:\n",
    "    \"\"\"把多种 hits 统一成 List[(node, score)]\"\"\"\n",
    "    out = []\n",
    "    for h in hits:\n",
    "        if hasattr(h, \"node\"):  # NodeWithScore\n",
    "            out.append((h.node, float(getattr(h, \"score\", 0.0))))\n",
    "        elif isinstance(h, TextNode):  # 直接 node\n",
    "            out.append((h, 0.0))\n",
    "        else:\n",
    "            try:\n",
    "                n, s = h\n",
    "                out.append((n, float(s)))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return out\n",
    "\n",
    "def _build_hit_row(n: TextNode, score: float, preview_chars: int = TEXT_PREVIEW_CHARS) -> HitRow:\n",
    "    ntype = (n.metadata or {}).get(\"node_type\", \"text\")\n",
    "    if ntype == \"figure\":\n",
    "        pr = (n.get_content() or \"\")\n",
    "        pr = pr.replace(\"\\n\", \" \").strip()\n",
    "        pr = pr[:preview_chars] + (\"…\" if len(pr) > preview_chars else \"\")\n",
    "        return HitRow(\n",
    "            node_id=n.node_id, node_type=\"figure\", score=score,\n",
    "            text_preview=pr,\n",
    "            fig_no=str((n.metadata or {}).get(\"fig_no\")),\n",
    "            fig_desc=(n.metadata or {}).get(\"fig_desc\") or \"\",\n",
    "            fig_path=(n.metadata or {}).get(\"fig_path\") or \"\",\n",
    "            fig_annos=(n.metadata or {}).get(\"fig_annos\") or \"\",\n",
    "        )\n",
    "    else:\n",
    "        pr = (n.get_content() or \"\")\n",
    "        pr = pr.replace(\"\\n\", \" \").strip()\n",
    "        pr = pr[:preview_chars] + (\"…\" if len(pr) > preview_chars else \"\")\n",
    "        return HitRow(\n",
    "            node_id=n.node_id, node_type=\"text\", score=score,\n",
    "            text_preview=pr,\n",
    "        )\n",
    "\n",
    "def print_rows(query: str, rows: List[HitRow], show: int = 10, show_annos_once: bool = True):\n",
    "    \"\"\"统一打印；附图标记说明（annos）只打印一次\"\"\"\n",
    "    print(f\"Q: {query}\\n\")\n",
    "    annos_printed = False\n",
    "    for i, r in enumerate(rows[:show], 1):\n",
    "        if r.node_type == \"figure\":\n",
    "            print(f\"{i:>2}. [FIG  ] score={r.score:.4f} | 图{r.fig_no} {r.fig_desc} | path={r.fig_path}\")\n",
    "            if show_annos_once and (not annos_printed) and r.fig_annos:\n",
    "                print(f\"    └─ 附图标记说明：{r.fig_annos[:200]}{'…' if len(r.fig_annos)>200 else ''}\")\n",
    "                annos_printed = True\n",
    "        else:\n",
    "            print(f\"{i:>2}. [TEXT ] score={r.score:.4f} | {r.text_preview}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32c15a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= ② Optional: BM25 资源 & “图N”快速映射 =========\n",
    "\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "HAS_BM25 = True\n",
    "\n",
    "\n",
    "# 需要：你已在之前单元拿到了 index, nodes_cache\n",
    "assert \"index\" in globals(), \"请先运行你构建索引的单元，获得 `index`。\"\n",
    "assert \"nodes_cache\" in globals(), \"请先运行你构建节点的单元，获得 `nodes_cache`。\"\n",
    "\n",
    "BM25_TOP_K_DEFAULT = 8  # 候选越多，融合时越有余地\n",
    "BM25_RET = None\n",
    "if USE_BM25 and HAS_BM25:\n",
    "    BM25_RET = BM25Retriever.from_defaults(nodes=nodes_cache, similarity_top_k=BM25_TOP_K_DEFAULT)\n",
    "\n",
    "# “图N”联动索引（text 命中里提到了图N时，补充相应 figure node）\n",
    "FIG_NODE_INDEX: Dict[int, TextNode] = {}\n",
    "for n in nodes_cache:\n",
    "    if (n.metadata or {}).get(\"node_type\") == \"figure\":\n",
    "        no_raw = (n.metadata or {}).get(\"fig_no\")\n",
    "        try:\n",
    "            k = int(str(no_raw).strip())\n",
    "            FIG_NODE_INDEX[k] = n\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79703fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VECTOR ===\n",
      "Q: 该专利发明了什么？\n",
      "\n",
      " 1. [TEXT ] score=1.1748 | # 著录信息 (19)中华人民共和国国家知识产权局  (12)实用新型专利  (10)授权公告号CN207225508U(45)授权公告日2018.04.13  (21)申请号201721328994.5  (22)申请日2017.10.16  (73)专利权人杭州宇树科技有限公司地址310051浙江省杭州市滨江区聚业路26号金绣国际科技中心B座106室  (72)发明人王兴兴 杨知雨  (74)…\n",
      " 2. [FIG  ] score=1.1866 | 图1 本实用新型整体结构示意图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\0b110668bdedeef913bee95d62f88cc6c1765ec83d8fd0cf83cbfe316729c0cf.jpg\n",
      "    └─ 附图标记说明：附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n",
      " 3. [TEXT ] score=1.2152 | [0013] 作为优选技术措施，所述足基座总成或保护罩总成外设有一凹槽，凹槽内安装一用于观测足端运动轨迹的发光件。所述发光件为LED灯，方便观测足端的运动轨迹，并且提高机器人的观赏性。  [0014] 与现有技术相比，本实用新型具有以下有益效果：  [0015] 本实用新型设置由高屈服强度材料制造而成的和具有特殊结构的敏感部，相比现有技术的机器人足端结构，所需的零部件少，结构简单，重量轻，便于生产…\n",
      " 4. [FIG  ] score=1.2187 | 图3 本实用新型爆炸视图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\2649e5073d9e380fe64058ca443c4bcb2bf8d6c0183067d83a025b530a406f7e.jpg\n",
      " 5. [TEXT ] score=1.2354 | 但是此方案结构复杂，重量及体积较大。  实用新型内容： [0004] 针对现有技术的缺陷，本实用新型的目的在于提供一种不易损坏、失效，结构简单，重量轻，体积紧凑，便于生产制造的低成本机器人足端结构，进一步，能够准确测量足端受力的机器人足端结构。  [0005] 为实现上述目的，本实用新型的技术方案为：  [0006] 一种机器人足端结构，包括用于和机器人腿部连杆相连接的足基座总成、用于缓冲传递冲击…\n",
      "\n",
      "=== BM25 ===\n",
      "Q: 该专利发明了什么？\n",
      "\n",
      " 1. [FIG  ] score=0.0000 | 图6 本实用新型设置发光件的结构示意图（不包括保护罩总成） | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\730d3218997db726e8df83cfee8bab58bd2a80709dd3b13590f9d5dc91bc494d.jpg\n",
      "    └─ 附图标记说明：附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n",
      " 2. [FIG  ] score=0.0000 | 图5 本实用新型部分结构示意图（不包括保护罩总成） | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\c13063d537ddc01148e49c7f83d4127ab3acbea6482574365a083c7f1efcb34e.jpg\n",
      " 3. [FIG  ] score=0.0000 | 图4 本实用新型局部爆炸视图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\906093d2fd363840626568d48a84b01cc75bf18892b5b8197140496dc648bfe0.jpg\n",
      " 4. [FIG  ] score=0.0000 | 图3 本实用新型爆炸视图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\2649e5073d9e380fe64058ca443c4bcb2bf8d6c0183067d83a025b530a406f7e.jpg\n",
      " 5. [FIG  ] score=0.0000 | 图2 本实用新型剖视图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\f6f4294118dd28c8f795d7c633a1e3bd99fad6f9422678f4dc7439d64982e4a8.jpg\n",
      "\n",
      "=== HYBRID ===\n",
      "Q: 该专利发明了什么？\n",
      "\n",
      " 1. [TEXT ] score=0.7000 | 但是此方案结构复杂，重量及体积较大。  实用新型内容： [0004] 针对现有技术的缺陷，本实用新型的目的在于提供一种不易损坏、失效，结构简单，重量轻，体积紧凑，便于生产制造的低成本机器人足端结构，进一步，能够准确测量足端受力的机器人足端结构。  [0005] 为实现上述目的，本实用新型的技术方案为：  [0006] 一种机器人足端结构，包括用于和机器人腿部连杆相连接的足基座总成、用于缓冲传递冲击…\n",
      " 2. [FIG  ] score=0.5070 | 图3 本实用新型爆炸视图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\2649e5073d9e380fe64058ca443c4bcb2bf8d6c0183067d83a025b530a406f7e.jpg\n",
      "    └─ 附图标记说明：附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n",
      " 3. [TEXT ] score=0.4672 | [0013] 作为优选技术措施，所述足基座总成或保护罩总成外设有一凹槽，凹槽内安装一用于观测足端运动轨迹的发光件。所述发光件为LED灯，方便观测足端的运动轨迹，并且提高机器人的观赏性。  [0014] 与现有技术相比，本实用新型具有以下有益效果：  [0015] 本实用新型设置由高屈服强度材料制造而成的和具有特殊结构的敏感部，相比现有技术的机器人足端结构，所需的零部件少，结构简单，重量轻，便于生产…\n",
      " 4. [FIG  ] score=0.1365 | 图1 本实用新型整体结构示意图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\0b110668bdedeef913bee95d62f88cc6c1765ec83d8fd0cf83cbfe316729c0cf.jpg\n",
      " 5. [TEXT ] score=0.0000 | # 著录信息 (19)中华人民共和国国家知识产权局  (12)实用新型专利  (10)授权公告号CN207225508U(45)授权公告日2018.04.13  (21)申请号201721328994.5  (22)申请日2017.10.16  (73)专利权人杭州宇树科技有限公司地址310051浙江省杭州市滨江区聚业路26号金绣国际科技中心B座106室  (72)发明人王兴兴 杨知雨  (74)…\n"
     ]
    }
   ],
   "source": [
    "# ========= ③ 检索模式：vector / bm25 / hybrid =========\n",
    "\n",
    "def vector_search(\n",
    "    index: VectorStoreIndex,\n",
    "    query: str,\n",
    "    *,\n",
    "    top_k: int = TOP_K,\n",
    "    vector_mode: str = VECTOR_MODE,\n",
    "    mmr_alpha: float = MMR_ALPHA,\n",
    ") -> List[Tuple[TextNode, float]]:\n",
    "    retriever = index.as_retriever(\n",
    "        similarity_top_k=top_k,\n",
    "        vector_store_query_mode=vector_mode,\n",
    "        alpha=mmr_alpha if vector_mode == \"mmr\" else None,\n",
    "    )\n",
    "    hits = retriever.retrieve(QueryBundle(query))\n",
    "    return _coerce_hits(hits)\n",
    "\n",
    "def bm25_search(\n",
    "    query: str,\n",
    "    *,\n",
    "    top_k: int = TOP_K,\n",
    ") -> List[Tuple[TextNode, float]]:\n",
    "    if not (USE_BM25 and HAS_BM25 and BM25_RET is not None):\n",
    "        return []\n",
    "    return _coerce_hits(BM25_RET.retrieve(query)[:top_k])\n",
    "\n",
    "def _normalize_scores(pairs: List[Tuple[TextNode, float]]) -> List[Tuple[TextNode, float, float]]:\n",
    "    \"\"\"min-max 归一化到 [0,1]，返回 (node, raw, norm)\"\"\"\n",
    "    if not pairs:\n",
    "        return []\n",
    "    vals = [s for _, s in pairs]\n",
    "    mx, mn = max(vals), min(vals)\n",
    "    rng = (mx - mn) or 1.0\n",
    "    out = []\n",
    "    for n, s in pairs:\n",
    "        out.append((n, s, (s - mn) / rng))\n",
    "    return out\n",
    "\n",
    "def hybrid_search(\n",
    "    index: VectorStoreIndex,\n",
    "    query: str,\n",
    "    *,\n",
    "    top_k: int = TOP_K,\n",
    "    w_vec: float = HYBRID_W_VEC,\n",
    "    w_bm25: float = HYBRID_W_BM25,\n",
    "    vector_mode: str = VECTOR_MODE,\n",
    "    mmr_alpha: float = MMR_ALPHA,\n",
    ") -> List[Tuple[TextNode, float]]:\n",
    "    vec_pairs = vector_search(index, query, top_k=top_k, vector_mode=vector_mode, mmr_alpha=mmr_alpha)\n",
    "    bm_pairs  = bm25_search(query, top_k=top_k)\n",
    "\n",
    "    vec_norm = _normalize_scores(vec_pairs)\n",
    "    bm_norm  = _normalize_scores(bm_pairs)\n",
    "\n",
    "    pool: Dict[str, Tuple[TextNode, float]] = {}\n",
    "    for n, _, nv in vec_norm:\n",
    "        pool[n.node_id] = (n, w_vec * nv)\n",
    "    for n, _, nb in bm_norm:\n",
    "        if n.node_id in pool:\n",
    "            old_n, old_s = pool[n.node_id]\n",
    "            pool[n.node_id] = (old_n, old_s + w_bm25 * nb)\n",
    "        else:\n",
    "            pool[n.node_id] = (n, w_bm25 * nb)\n",
    "\n",
    "    merged = sorted(pool.values(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return merged\n",
    "\n",
    "# ---- 简单试跑 ----\n",
    "for mode_name, fn in [\n",
    "    (\"vector\", lambda q: vector_search(index, q, top_k=5)),\n",
    "    (\"bm25\",   lambda q: bm25_search(q, top_k=5)),\n",
    "    (\"hybrid\", lambda q: hybrid_search(index, q, top_k=5)),\n",
    "]:\n",
    "    q = \"该专利发明了什么？\"\n",
    "    pairs = fn(q)\n",
    "    rows = [_build_hit_row(n, s) for n, s in pairs]\n",
    "    print(f\"\\n=== {mode_name.upper()} ===\")\n",
    "    print_rows(q, rows, show=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3806aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 该专利发明了什么东西？\n",
      "=============1==============\n",
      "Node ID: ff8b8347-cde3-5220-be5e-4e0182b7c773::fig::1\n",
      "Text: 图1为本实用新型整体结构示意图\n",
      "Score:  1.160\n",
      "\n",
      " 1. [figure] 图1 - 本实用新型整体结构示意图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\0b110668bdedeef913bee95d62f88cc6c1765ec83d8fd0cf83cbfe316729c0cf.jpg  | score=1.1596\n",
      "\n",
      "\n",
      "=============2==============\n",
      "Node ID: ff8b8347-cde3-5220-be5e-4e0182b7c773::text::1\n",
      "Text: # 著录信息 (19)中华人民共和国国家知识产权局  (12)实用新型专利\n",
      "(10)授权公告号CN207225508U(45)授权公告日2018.04.13  (21)申请号201721328994.5\n",
      "(22)申请日2017.10.16\n",
      "(73)专利权人杭州宇树科技有限公司地址310051浙江省杭州市滨江区聚业路26号金绣国际科技中心B座106室  (72)发明人王兴兴\n",
      "杨知雨  (74)专利代理机构浙江翔隆专利事务所（普通合伙）33206  代理人许守金  (51)Int.Cl.\n",
      "B62D57/032(2006.01) G01L1/18(2006.01) G01C21/10(2006.01)  权利要求书1页\n",
      "说明书4页 附图4页  (54)实用新型名称  一种机器人足端结构...\n",
      "Score:  1.160\n",
      "\n",
      " 2. [text] # 著录信息 (19)中华人民共和国国家知识产权局  (12)实用新型专利  (10)授权公告号CN207225508U(45)授权公告日2018.04.13  (21)申请号201721328994.5  (22)申请日2017.10.1…  | score=1.1600\n",
      "\n",
      "\n",
      "=============3==============\n",
      "Node ID: ff8b8347-cde3-5220-be5e-4e0182b7c773::text::8\n",
      "Text: [0013] 作为优选技术措施，所述足基座总成或保护罩总成外设有一凹槽，凹槽内安装一用于观测足端运动轨迹的发光件。所述发光件为L\n",
      "ED灯，方便观测足端的运动轨迹，并且提高机器人的观赏性。  [0014] 与现有技术相比，本实用新型具有以下有益效果：  [0015] 本实\n",
      "用新型设置由高屈服强度材料制造而成的和具有特殊结构的敏感部，相比现有技术的机器人足端结构，所需的零部件少，结构简单，重量轻，便于生产制造，不\n",
      "易因外力过载而失效，制造成本低。  [0016] 进一步，本实用新型的应变片黏贴于敏感部上，能够准确感应传感部件的形变位移，把支撑力的大小转\n",
      "化为自身电阻变化的大小，进而实现对足端受力的测量并且测量精度高。  具体实施方式： [0025]\n",
      "为了使本实用新型的目的、技术方案及优点更加清楚明...\n",
      "Score:  1.198\n",
      "\n",
      " 3. [text] [0013] 作为优选技术措施，所述足基座总成或保护罩总成外设有一凹槽，凹槽内安装一用于观测足端运动轨迹的发光件。所述发光件为LED灯，方便观测足端的运动轨迹，并且提高机器人的观赏性。  [0014] 与现有技术相比，本实用新型具有以下有益…  | score=1.1984\n",
      "\n",
      "\n",
      "=============4==============\n",
      "Node ID: ff8b8347-cde3-5220-be5e-4e0182b7c773::fig::3\n",
      "Text: 图3为本实用新型爆炸视图\n",
      "Score:  1.199\n",
      "\n",
      " 4. [figure] 图3 - 本实用新型爆炸视图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\2649e5073d9e380fe64058ca443c4bcb2bf8d6c0183067d83a025b530a406f7e.jpg  | score=1.1988\n",
      "\n",
      "\n",
      "=============5==============\n",
      "Node ID: ff8b8347-cde3-5220-be5e-4e0182b7c773::text::5\n",
      "Text: 但是此方案结构复杂，重量及体积较大。  实用新型内容： [0004] 针对现有技术的缺陷，本实用新型的目的在于提供一种不易损坏、\n",
      "失效，结构简单，重量轻，体积紧凑，便于生产制造的低成本机器人足端结构，进一步，能够准确测量足端受力的机器人足端结构。  [0005]\n",
      "为实现上述目的，本实用新型的技术方案为：  [0006] 一种机器人足端结构，包括用于和机器人腿部连杆相连接的足基座总成、用于缓冲传递冲击力\n",
      "的足垫和用于保护足内部结构的保护罩总成，所述足基座总成内的传感部件上设有能产生较大变形的敏感部，所述敏感部由高屈服强度材料制成；所述足垫传递\n",
      "足受到的支撑力到足基座总成，使敏感部产生较大变形。所述机器人腿部连杆与传感部件可以一体制成，也可以通过焊接或者螺钉连接的方式相连接。本实用新\n",
      "型设置的传感...\n",
      "Score:  1.214\n",
      "\n",
      " 5. [text] 但是此方案结构复杂，重量及体积较大。  实用新型内容： [0004] 针对现有技术的缺陷，本实用新型的目的在于提供一种不易损坏、失效，结构简单，重量轻，体积紧凑，便于生产制造的低成本机器人足端结构，进一步，能够准确测量足端受力的机器人足端结…  | score=1.2139\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# retriever \n",
    "# ==== ① 向量检索参数 & 展示工具 ====\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "from llama_index.core import QueryBundle\n",
    "\n",
    "# 超参数（随手改）\n",
    "TOP_K = 8                       # 向量检索返回条数\n",
    "VECTOR_MODE = \"mmr\"         # 可选: \"default\" | \"mmr\"\n",
    "MMR_ALPHA = 0.5                 # 仅当 VECTOR_MODE=\"mmr\" 生效，0~1，越大越多样化\n",
    "\n",
    "# 简单预处理：看看用户是否在问“图N”\n",
    "FIG_PAT = re.compile(r\"图\\s*([0-9０-９]+)\")\n",
    "\n",
    "def _has_fig_mention(q: str) -> List[int]:\n",
    "    \"\"\"检测 query 里有没有“图N”，返回命中的图号列表（半角化）\"\"\"\n",
    "    nums = []\n",
    "    for m in FIG_PAT.finditer(q or \"\"):\n",
    "        s = m.group(1).translate(str.maketrans(\"０１２３４５６７８９\",\"0123456789\"))\n",
    "        try:\n",
    "            nums.append(int(s))\n",
    "        except:\n",
    "            pass\n",
    "    return nums\n",
    "\n",
    "def preview_hit(hit, max_chars: int = 120) -> str:\n",
    "    \"\"\"把 NodeWithScore 变成一行可读文本\"\"\"\n",
    "    n = hit.node\n",
    "    kind = n.metadata.get(\"node_type\", \"text\")\n",
    "    if kind == \"figure\":\n",
    "        fig_no = n.metadata.get(\"fig_no\",\"?\")\n",
    "        fig_desc = n.metadata.get(\"fig_desc\",\"\")\n",
    "        fig_path = n.metadata.get(\"fig_path\",\"\")\n",
    "        return f\"[figure] 图{fig_no} - {fig_desc}  | path={fig_path}  | score={hit.score:.4f}\"\n",
    "    else:\n",
    "        text = (n.get_content() or \"\").replace(\"\\n\",\" \").strip()\n",
    "        return f\"[text] {text[:max_chars]}{'…' if len(text)>max_chars else ''}  | score={hit.score:.4f}\"\n",
    "\n",
    "# retriever \n",
    "\n",
    "\n",
    "# ==== ② 基础向量检索 ====\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "def vector_search(query: str, top_k: int = TOP_K) -> List[Any]:\n",
    "    retriever = index.as_retriever(\n",
    "        similarity_top_k=top_k,\n",
    "        vector_store_query_mode=VECTOR_MODE,\n",
    "        alpha=MMR_ALPHA if VECTOR_MODE == \"mmr\" else None,\n",
    "    )\n",
    "    hits = retriever.retrieve(QueryBundle(query))\n",
    "    return hits\n",
    "\n",
    "# --- 小测试 ---\n",
    "q = \"该专利发明了什么东西？\"\n",
    "hits = vector_search(q, top_k=5)\n",
    "print(\"Q:\", q)\n",
    "for i, h in enumerate(hits, 1):\n",
    "    print(f\"============={i}==============\")\n",
    "    print(h)\n",
    "    print(f\"{i:>2}.\", preview_hit(h))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8695e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 介绍一下这个专利\n",
      " 1. [figure] 图6 - 本实用新型设置发光件的结构示意图（不包括保护罩总成）  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\730d3218997db726e8df83cfee8bab58bd2a80709dd3b13590f9d5dc91bc494d.jpg  | score=0.7000\n",
      " 2. [figure] 图abs - 摘要图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\88fe5b0e5b16afc42f78352f8df13f234eeb58b135cdcfdfea80134da7580363.jpg  | score=0.4828\n",
      " 3. [figure] 图5 - 本实用新型部分结构示意图（不包括保护罩总成）  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\c13063d537ddc01148e49c7f83d4127ab3acbea6482574365a083c7f1efcb34e.jpg  | score=0.4643\n",
      " 4. [text] # 著录信息 (19)中华人民共和国国家知识产权局  (12)实用新型专利  (10)授权公告号CN207225508U(45)授权公告日2018.04.13  (21)申请号201721328994.5  (22)申请日2017.10.1…  | score=0.4368\n",
      " 5. [figure] 图4 - 本实用新型局部爆炸视图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\906093d2fd363840626568d48a84b01cc75bf18892b5b8197140496dc648bfe0.jpg  | score=0.3972\n",
      " 6. [figure] 图2 - 本实用新型剖视图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\f6f4294118dd28c8f795d7c633a1e3bd99fad6f9422678f4dc7439d64982e4a8.jpg  | score=0.3240\n",
      " 7. [figure] 图3 - 本实用新型爆炸视图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\2649e5073d9e380fe64058ca443c4bcb2bf8d6c0183067d83a025b530a406f7e.jpg  | score=0.2052\n",
      " 8. [figure] 图1 - 本实用新型整体结构示意图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\0b110668bdedeef913bee95d62f88cc6c1765ec83d8fd0cf83cbfe316729c0cf.jpg  | score=0.0000\n"
     ]
    }
   ],
   "source": [
    "# retriever \n",
    "# 纯工程做法：用 BM25 对 nodes_cache（你前面 build 的文本/图片节点汇总）做关键词匹配，然后和向量检索融合。\n",
    "# ==== ③ BM25 + 混合检索（可选） ====\n",
    "try:\n",
    "    from llama_index.retrievers.bm25 import BM25Retriever\n",
    "    HAS_BM25 = True\n",
    "except Exception:\n",
    "    HAS_BM25 = False\n",
    "\n",
    "# 融合权重（可调）\n",
    "W_VEC = 0.7\n",
    "W_BM25 = 0.3\n",
    "\n",
    "def _merge_scores(vec_hits, bm_hits, top_k=TOP_K) -> List[Any]:\n",
    "    \"\"\"把两路结果按加权分数融合，返回前 top_k 的 NodeWithScore 列表\"\"\"\n",
    "    # 归一化\n",
    "    def _norm_scores(hits):\n",
    "        if not hits:\n",
    "            return []\n",
    "        scores = [h.score for h in hits if h.score is not None]\n",
    "        if not scores:\n",
    "            return hits\n",
    "        mx, mn = max(scores), min(scores)\n",
    "        rng = (mx - mn) or 1.0\n",
    "        for h in hits:\n",
    "            h._norm = (h.score - mn) / rng if h.score is not None else 0.0\n",
    "        return hits\n",
    "\n",
    "    vec_hits = _norm_scores(list(vec_hits))\n",
    "    bm_hits  = _norm_scores(list(bm_hits))\n",
    "\n",
    "    pool: Dict[str, Dict[str, Any]] = {}\n",
    "    def _accumulate(hits, w):\n",
    "        for h in hits:\n",
    "            nid = h.node.node_id\n",
    "            if nid not in pool:\n",
    "                pool[nid] = {\"node\": h.node, \"score\": 0.0, \"v\": 0.0, \"b\": 0.0}\n",
    "            pool[nid][\"score\"] += w * getattr(h, \"_norm\", 0.0)\n",
    "            pool[nid][\"v\"] += (w * getattr(h, \"_norm\", 0.0) if w==W_VEC else 0.0)\n",
    "            pool[nid][\"b\"] += (w * getattr(h, \"_norm\", 0.0) if w==W_BM25 else 0.0)\n",
    "\n",
    "    _accumulate(vec_hits, W_VEC)\n",
    "    _accumulate(bm_hits,  W_BM25)\n",
    "\n",
    "    # 排序&构造 NodeWithScore\n",
    "    merged = sorted(pool.values(), key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
    "    out = []\n",
    "    from llama_index.core.schema import NodeWithScore\n",
    "    for it in merged:\n",
    "        out.append(NodeWithScore(node=it[\"node\"], score=it[\"score\"]))\n",
    "    return out\n",
    "\n",
    "def hybrid_search(query: str, top_k: int = TOP_K) -> List[Any]:\n",
    "    # 向量路\n",
    "    vec_hits = vector_search(query, top_k=top_k)\n",
    "\n",
    "    # 词匹配路（可选）\n",
    "    if HAS_BM25 and nodes_cache:\n",
    "        bm25 = BM25Retriever.from_defaults(nodes=nodes_cache, similarity_top_k=top_k)\n",
    "        bm_hits = bm25.retrieve(query)\n",
    "    else:\n",
    "        bm_hits = []\n",
    "\n",
    "    # 融合\n",
    "    merged = _merge_scores(vec_hits, bm_hits, top_k=top_k)\n",
    "    return merged\n",
    "\n",
    "# --- 小测试 ---\n",
    "q = \"介绍一下这个专利\"\n",
    "hits = hybrid_search(q, top_k=8)\n",
    "print(\"Q:\", q)\n",
    "for i, h in enumerate(hits, 1):\n",
    "    print(f\"{i:>2}.\", preview_hit(h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dbae5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 介绍一下这个专利的标题\n",
      " 1. [figure] 图abs - 摘要图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\88fe5b0e5b16afc42f78352f8df13f234eeb58b135cdcfdfea80134da7580363.jpg  | score=0.7000\n",
      "    └─ annos: 附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n",
      " 2. [text] # 著录信息 (19)中华人民共和国国家知识产权局  (12)实用新型专利  (10)授权公告号CN207225508U(45)授权公告日2018.04.13  (21)申请号201721328994.5  (22)申请日2017.10.1…  | score=0.5774\n",
      " 3. [figure] 图4 - 本实用新型局部爆炸视图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\906093d2fd363840626568d48a84b01cc75bf18892b5b8197140496dc648bfe0.jpg  | score=0.5573\n",
      "    └─ annos: 附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n",
      " 4. [figure] 图2 - 本实用新型剖视图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\f6f4294118dd28c8f795d7c633a1e3bd99fad6f9422678f4dc7439d64982e4a8.jpg  | score=0.4422\n",
      "    └─ annos: 附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n",
      " 5. [figure] 图3 - 本实用新型爆炸视图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\2649e5073d9e380fe64058ca443c4bcb2bf8d6c0183067d83a025b530a406f7e.jpg  | score=0.2303\n",
      "    └─ annos: 附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n",
      " 6. [figure] 图1 - 本实用新型整体结构示意图  | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\0b110668bdedeef913bee95d62f88cc6c1765ec83d8fd0cf83cbfe316729c0cf.jpg  | score=0.0000\n",
      "    └─ annos: 附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n"
     ]
    }
   ],
   "source": [
    "# retriever \n",
    "# ==== ④ 高级检索：支持“图N”偏好 + 统一打印 ====\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "PREFER_FIG_BOOST = 0.02   # 出现“图N”时，对齐编号的 figure 节点加一个小偏置\n",
    "\n",
    "def search(query: str, top_k: int = TOP_K, use_hybrid: bool = True, prefer_fig: bool = True) -> List[NodeWithScore]:\n",
    "    # 1) 基础检索\n",
    "    hits = hybrid_search(query, top_k=top_k) if use_hybrid else vector_search(query, top_k=top_k)\n",
    "\n",
    "    # 2) 如果 query 里写了“图N”，对命中同号的 figure 轻度加权（不改变原有分数体系）\n",
    "    if prefer_fig:\n",
    "        fig_ids = set(_has_fig_mention(query))\n",
    "        if fig_ids:\n",
    "            boosted = []\n",
    "            for h in hits:\n",
    "                n = h.node\n",
    "                kind = n.metadata.get(\"node_type\")\n",
    "                if kind == \"figure\":\n",
    "                    try:\n",
    "                        no = int(str(n.metadata.get(\"fig_no\",\"\")).strip())\n",
    "                    except:\n",
    "                        no = None\n",
    "                    if no in fig_ids:\n",
    "                        # 构造一个新的 NodeWithScore，增加一点偏置\n",
    "                        boosted.append(NodeWithScore(node=n, score=(h.score or 0.0) + PREFER_FIG_BOOST))\n",
    "                        continue\n",
    "                boosted.append(h)\n",
    "            # 重新排序\n",
    "            hits = sorted(boosted, key=lambda x: x.score or 0.0, reverse=True)[:top_k]\n",
    "\n",
    "    return hits\n",
    "\n",
    "def print_results(query: str, hits: List[NodeWithScore], show=10):\n",
    "    print(f\"Q: {query}\")\n",
    "    for i, h in enumerate(hits[:show], 1):\n",
    "        print(f\"{i:>2}.\", preview_hit(h))\n",
    "        # 如是配图，还可以补充打印 annos（附图标记说明）\n",
    "        if h.node.metadata.get(\"node_type\") == \"figure\":\n",
    "            ann = h.node.metadata.get(\"fig_annos\",\"\")\n",
    "            if ann:\n",
    "                print(\"    └─ annos:\", ann[:140] + (\"…\" if len(ann)>140 else \"\"))\n",
    "\n",
    "# --- 小测试：包含“图1”的偏好 ---\n",
    "q = \"介绍一下这个专利的标题\"\n",
    "hits = search(q, top_k=6, use_hybrid=True, prefer_fig=True)\n",
    "print_results(q, hits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c238a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 请解释图2的含义，并引用对应段落\n",
      " 1. [TEXT] 对本领域技术人员来说没有这些细节部分的描述也可以完全理解本实用新型。  [0027] 需要说明的是，当元件被称为“固定于”另一个元件，它可以直接在另一个元件上或者也可以存在居中的元件。当一个元件被认为是“连接”另一个元件，它可以是直接连接到另一个元件或者可能同时存在居中元件。相反，当元件被称作“直接在”另一元件“上”时… | score=0.7000\n",
      " 2. [FIG 6] 本实用新型设置发光件的结构示意图（不包括保护罩总成） | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\730d3218997db726e8df83cfee8bab58bd2a80709dd3b13590f9d5dc91bc494d.jpg | score=0.6600\n",
      "    └─ 附图标记说明： 附图标记说明：1：保护罩总成，2：足基座总成，3：足垫，2-1：传感部件，2-2：应变片，2-3：发光件，2-4：测控单元，2-5：足基座，2-1- 1：敏感部，2-1- 1-1：平行平面区域\n",
      " 3. [FIG 5] 本实用新型部分结构示意图（不包括保护罩总成） | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\c13063d537ddc01148e49c7f83d4127ab3acbea6482574365a083c7f1efcb34e.jpg | score=0.5860\n",
      " 4. [FIG 4] 本实用新型局部爆炸视图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\906093d2fd363840626568d48a84b01cc75bf18892b5b8197140496dc648bfe0.jpg | score=0.3739\n",
      " 5. [FIG 3] 本实用新型爆炸视图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\2649e5073d9e380fe64058ca443c4bcb2bf8d6c0183067d83a025b530a406f7e.jpg | score=0.2906\n",
      " 6. [FIG 1] 本实用新型整体结构示意图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\0b110668bdedeef913bee95d62f88cc6c1765ec83d8fd0cf83cbfe316729c0cf.jpg | score=0.2875\n",
      " 7. [FIG 2] 本实用新型剖视图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\f6f4294118dd28c8f795d7c633a1e3bd99fad6f9422678f4dc7439d64982e4a8.jpg | score=0.1201\n",
      " 8. [FIG abs] 摘要图 | path=D:\\codespace\\fhfeishi\\raga\\.log\\SimplePDF\\CN201721328994.5-一种机器人足端结构.pdf-e856a75f-7fe7-4813-a860-05ca62419ac7\\images\\88fe5b0e5b16afc42f78352f8df13f234eeb58b135cdcfdfea80134da7580363.jpg | score=0.0000\n"
     ]
    }
   ],
   "source": [
    "# ==== ② 检索 + “图N”联动 + annos 一次性输出 ====\n",
    "\n",
    "import re\n",
    "from typing import Dict\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "FIG_PAT = re.compile(r\"图\\s*([0-9０-９]+)\")\n",
    "_DIGIT_TRANS = str.maketrans(\"０１２３４５６７８９\", \"0123456789\")\n",
    "\n",
    "def _fig_nums_in_text(s: str) -> List[int]:\n",
    "    out = []\n",
    "    for m in FIG_PAT.finditer(s or \"\"):\n",
    "        try:\n",
    "            out.append(int(m.group(1).translate(_DIGIT_TRANS)))\n",
    "        except:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "# 为“图N联动”做个缓存索引：fig_no -> figure_node（从 nodes_cache 构建一次即可）\n",
    "def build_fig_index(nodes_cache: List[TextNode]) -> Dict[int, TextNode]:\n",
    "    idx: Dict[int, TextNode] = {}\n",
    "    for n in nodes_cache:\n",
    "        if n.metadata.get(\"node_type\") == \"figure\":\n",
    "            no = n.metadata.get(\"fig_no\")\n",
    "            try:\n",
    "                k = int(str(no).strip())\n",
    "                idx[k] = n\n",
    "            except Exception:\n",
    "                pass\n",
    "    return idx\n",
    "\n",
    "FIG_NODE_INDEX = build_fig_index(nodes_cache)\n",
    "\n",
    "def retrieve(query: str, k: int = 8, use_hybrid: bool = True) -> List[NodeWithScore]:\n",
    "    hits = hybrid_search(query, top_k=k) if use_hybrid else vector_search(query, top_k=k)\n",
    "\n",
    "    # 文本命中里提到“图N”，联动补上对应 figure 节点（不重复）\n",
    "    wanted_figs = set()\n",
    "    for h in hits:\n",
    "        if h.node.metadata.get(\"node_type\") == \"text\":\n",
    "            wanted_figs.update(_fig_nums_in_text(h.node.get_content()))\n",
    "\n",
    "    # 把缺失的 figure node 加入（score 给个轻微 boost）\n",
    "    node_ids = set(h.node.node_id for h in hits)\n",
    "    extra: List[NodeWithScore] = []\n",
    "    for n in sorted(wanted_figs):\n",
    "        if n in FIG_NODE_INDEX:\n",
    "            fn = FIG_NODE_INDEX[n]\n",
    "            if fn.node_id not in node_ids:\n",
    "                extra.append(NodeWithScore(node=fn, score=(hits[-1].score if hits else 0.0) + 1e-6))\n",
    "\n",
    "    all_hits = hits + extra\n",
    "    # 重新排序后截断\n",
    "    all_hits = sorted(all_hits, key=lambda x: x.score or 0.0, reverse=True)[:k]\n",
    "    return all_hits\n",
    "\n",
    "def render_answer(query: str, hits: List[NodeWithScore], show: int = 8) -> None:\n",
    "    print(\"Q:\", query)\n",
    "    annos_printed = False\n",
    "    for i, h in enumerate(hits[:show], 1):\n",
    "        n = h.node\n",
    "        kind = n.metadata.get(\"node_type\")\n",
    "        if kind == \"figure\":\n",
    "            no   = n.metadata.get(\"fig_no\")\n",
    "            desc = n.metadata.get(\"fig_desc\",\"\")\n",
    "            path = n.metadata.get(\"fig_path\",\"\")\n",
    "            print(f\"{i:>2}. [FIG {no}] {desc} | path={path} | score={h.score:.4f}\")\n",
    "            # 附图标记说明只打印一次\n",
    "            if not annos_printed and (n.metadata.get(\"fig_annos\") or \"\").strip():\n",
    "                ann = n.metadata[\"fig_annos\"]\n",
    "                print(\"    └─ 附图标记说明：\", ann[:200] + (\"…\" if len(ann) > 200 else \"\"))\n",
    "                annos_printed = True\n",
    "        else:\n",
    "            txt = (n.get_content() or \"\").replace(\"\\n\",\" \").strip()\n",
    "            print(f\"{i:>2}. [TEXT] {txt[:160]}{'…' if len(txt)>160 else ''} | score={h.score:.4f}\")\n",
    "\n",
    "\n",
    "q = \"请解释图2的含义，并引用对应段落\"\n",
    "hits = retrieve(q, k=8, use_hybrid=True)\n",
    "render_answer(q, hits, show=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d929a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever \n",
    "\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "def _coerce_hits(hits: Iterable) -> List[Tuple[TextNode, float]]:\n",
    "    out = []\n",
    "    for h in hits:\n",
    "        if hasattr(h, \"node\"):  # NodeWithScore\n",
    "            out.append((h.node, float(getattr(h, \"score\", 0.0))))\n",
    "        elif isinstance(h, TextNode):  # Node\n",
    "            out.append((h, 0.0))\n",
    "        else:\n",
    "            try:\n",
    "                n, s = h\n",
    "                out.append((n, float(s)))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return out\n",
    "\n",
    "def retrieve_nodes(\n",
    "    index: VectorStoreIndex,\n",
    "    query: str,\n",
    "    top_k: int = 3, # \n",
    "    *,\n",
    "    use_hybrid: bool = False, #  \n",
    "    bm25_top_k: int = 5,\n",
    "    bm25_nodes: Optional[List[TextNode]] = None,\n",
    "    doc_id_filter: Optional[str] = None,\n",
    ") -> List[Tuple[TextNode, float]]:\n",
    "    if not (use_hybrid and HAS_BM25):\n",
    "        retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "        pairs = _coerce_hits(retriever.retrieve(query))\n",
    "        if doc_id_filter:\n",
    "            pairs = [(n, s) for n, s in pairs if n.metadata.get(\"doc_id\") == doc_id_filter]\n",
    "        return pairs[:top_k]\n",
    "\n",
    "    # Hybrid：BM25 + Vector 简单融合\n",
    "    if bm25_nodes is None:\n",
    "        bm25_nodes = nodes_cache\n",
    "    bm25 = BM25Retriever.from_text_nodes(bm25_nodes, similarity_top_k=bm25_top_k)\n",
    "    bm25_hits = _coerce_hits(bm25.retrieve(query))\n",
    "    vec_hits  = _coerce_hits(index.as_retriever(similarity_top_k=top_k).retrieve(query))\n",
    "\n",
    "    pool: Dict[str, Tuple[TextNode, float]] = {}\n",
    "    if bm25_hits:\n",
    "        max_b = max(s for _, s in bm25_hits) or 1.0\n",
    "        for n, s in bm25_hits:\n",
    "            pool[n.node_id] = (n, 0.6 * (s / max_b))\n",
    "    if vec_hits:\n",
    "        max_v = max(s for _, s in vec_hits) or 1.0\n",
    "        for n, s in vec_hits:\n",
    "            w = 0.7 * (s / max_v)\n",
    "            if n.node_id in pool:\n",
    "                old_n, old_s = pool[n.node_id]\n",
    "                pool[n.node_id] = (old_n, old_s + w)\n",
    "            else:\n",
    "                pool[n.node_id] = (n, w)\n",
    "\n",
    "    merged = sorted(pool.values(), key=lambda x: x[1], reverse=True)\n",
    "    pairs = merged[:top_k]\n",
    "    if doc_id_filter:\n",
    "        pairs = [(n, s) for n, s in pairs if n.metadata.get(\"doc_id\") == doc_id_filter]\n",
    "    return pairs[:top_k]\n",
    "\n",
    "def pretty_print_hits(pairs: List[Tuple[TextNode, float]], preview_chars: int = 260):\n",
    "    for i, (n, s) in enumerate(pairs, 1):\n",
    "        mt = n.metadata or {}\n",
    "        ntype = mt.get(\"node_type\", \"text\")\n",
    "        print(f\"\\n[{i}] score={s:.4f}  id={n.node_id}  type={ntype}\")\n",
    "        if ntype == \"figure\":\n",
    "            print(f\"  图号   : {mt.get('fig_no')}\")\n",
    "            print(f\"  描述   : {mt.get('fig_desc')}\")\n",
    "            print(f\"  路径   : {mt.get('fig_path')}\")\n",
    "            ann = (mt.get('fig_annos') or \"\")\n",
    "            if ann:\n",
    "                print(f\"  标记   : {(ann[:160] + '…') if len(ann)>160 else ann}\")\n",
    "            print(\"  ——向量文本——\")\n",
    "        print(n.get_content()[:preview_chars] + (\"…\" if len(n.get_content()) > preview_chars else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf98ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交互式检索示例（你可反复改 query）\n",
    "\n",
    "# 可选：只查某一份文档（按 doc_id 过滤）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881ffe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
