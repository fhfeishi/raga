{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step0: patent.md \n",
    "\n",
    "# step1:  split to :  figs_MetaDict.json   full_filtered.md  -split\n",
    "#  文本信息、图片引用 可以嵌入了\n",
    "# -> full_split.md\n",
    "# step2: full_filtered.md -->  struct: # 著录信息  # 权利要求书   # 说明书 \n",
    "#   ---> str\n",
    "# -> full_split_split.md\n",
    "# step3: extractor                     record      claims         specification\n",
    "#                         def record_extractor  claims_extractor  specification_extractor\n",
    "#   --->  norm_(str) \n",
    "#  \n",
    "# --> full_split_split_norm.md\n",
    "# 代码逻辑可能存在复用的可能  code ++\n",
    "\n",
    "# [xxxx] 以开头的段落  去掉[xxxx]\n",
    "# 无关的内容也可以去掉，\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split   raw full.md\n",
    "# ->  figs.json    full_split.md   \n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import mimetypes\n",
    "from typing import Dict, Tuple, List, Any, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------- 正则 --------------------\n",
    "IMG_MD_RE = re.compile(r'!\\[(?P<alt>[^\\]]*)\\]\\((?P<path>[^)]+)\\)', re.IGNORECASE)\n",
    "HEADER_RE = re.compile(r'^\\s*#{1,6}\\s*(?P<title>.+?)\\s*$', re.MULTILINE)\n",
    "ABSTRACT_HEADER_RE = re.compile(r'^\\s*#\\s*(?:\\(57\\))?\\s*摘要\\s*$', re.MULTILINE)\n",
    "FIGDESC_HEADER_RE = re.compile(r'^\\s*#\\s*附图说明\\s*$', re.MULTILINE)\n",
    "CN_INDEX_TAG_RE = re.compile(r'\\[\\s*\\d{3,}\\s*\\]')  # [0017] 这类编号\n",
    "\n",
    "# -------------------- 工具函数：构建 figs.json --------------------\n",
    "_DIGIT_TRANS = str.maketrans(\"０１２３４５６７８９\", \"0123456789\")\n",
    "\n",
    "def _to_ascii_digits(s: str) -> str:\n",
    "    return s.translate(_DIGIT_TRANS)\n",
    "\n",
    "def _clean_desc(desc: str) -> str:\n",
    "    \"\"\"把'图N为/是/:'去掉，保留后半句。\"\"\"\n",
    "    s = desc.strip()\n",
    "    m = re.match(r'^图\\s*([0-9０-９]+)\\s*[:：\\s]*(是|为)?\\s*', s)\n",
    "    if m:\n",
    "        return s[m.end():].strip()\n",
    "    return s\n",
    "\n",
    "def _to_path_str(p: Any) -> Optional[str]:\n",
    "    if not p:\n",
    "        return None\n",
    "    return str(p)\n",
    "\n",
    "def _img_to_b64(path_str: Optional[str],\n",
    "                include_b64: bool,\n",
    "                safe_read: bool,\n",
    "                max_b64_mb: float,\n",
    "                data_uri: bool) -> str:\n",
    "    if not include_b64 or not path_str:\n",
    "        return \"\"\n",
    "    try:\n",
    "        if safe_read and not os.path.exists(path_str):\n",
    "            return \"\"\n",
    "        sz = os.path.getsize(path_str)\n",
    "        if max_b64_mb and sz > max_b64_mb * 1024 * 1024:\n",
    "            return \"\"\n",
    "        with open(path_str, \"rb\") as f:\n",
    "            b64 = base64.b64encode(f.read()).decode(\"ascii\")\n",
    "        if data_uri:\n",
    "            mime = mimetypes.guess_type(path_str)[0] or \"image/jpeg\"\n",
    "            return f\"data:{mime};base64,{b64}\"\n",
    "        return b64\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def build_figs_repo(\n",
    "    figs: Dict[str, Any],\n",
    "    *,\n",
    "    include_b64: bool = True,\n",
    "    include_path: bool = False,\n",
    "    safe_read: bool = True,\n",
    "    max_b64_mb: float = 8.0,\n",
    "    data_uri: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"把 figs_MetaDict 规范化为可直接入库/前端使用的结构（均可 JSON 序列化）。\"\"\"\n",
    "    repo: Dict[str, Any] = {\n",
    "        # 摘要图: [path_str | None, base64_str]\n",
    "        \"im_abs\": [None, \"\"],\n",
    "        # 图号 -> 描述（去掉“图N为/是”）\n",
    "        \"ims_desc\": {},\n",
    "        # 图号 -> 绝对路径（字符串；按开关）\n",
    "        \"ims_absp\": {},\n",
    "        # 图号 -> base64（按开关）\n",
    "        \"ims_bs64\": {},\n",
    "        # 附图标记说明（“漂亮字符串”/原始）\n",
    "        \"ims_annos\": figs.get(\"annos_ims\", \"\").strip(),\n",
    "    }\n",
    "\n",
    "    # 兼容 im_abs / img_abs\n",
    "    abs_entry = figs.get(\"im_abs\") or figs.get(\"img_abs\")\n",
    "    if isinstance(abs_entry, list) and len(abs_entry) >= 2:\n",
    "        abs_path_str = _to_path_str(abs_entry[1])\n",
    "        abs_b64 = _img_to_b64(abs_path_str, include_b64, safe_read, max_b64_mb, data_uri)\n",
    "        repo[\"im_abs\"] = [abs_path_str if include_path else None, abs_b64]\n",
    "\n",
    "    # 逐个图条目：im_1, im_2, ...\n",
    "    for k, v in figs.items():\n",
    "        m = re.match(r'^im[_-]?(\\d+)$', k)\n",
    "        if not m:\n",
    "            continue\n",
    "        n = int(_to_ascii_digits(m.group(1)))\n",
    "        if isinstance(v, list) and len(v) >= 2:\n",
    "            desc_raw, p = v[0], v[1]\n",
    "            desc_clean = _clean_desc(str(desc_raw))\n",
    "            repo[\"ims_desc\"][n] = desc_clean or str(desc_raw).strip()\n",
    "\n",
    "            p_str = _to_path_str(p)\n",
    "            if include_path and p_str:\n",
    "                repo[\"ims_absp\"][n] = p_str\n",
    "            if include_b64:\n",
    "                repo[\"ims_bs64\"][n] = _img_to_b64(p_str, include_b64, safe_read, max_b64_mb, data_uri)\n",
    "\n",
    "    # 兜底：如果没有从 im_n 抽到描述，尝试从 lines_ims 里扫\n",
    "    if not repo[\"ims_desc\"] and isinstance(figs.get(\"lines_ims\"), list):\n",
    "        for line in figs[\"lines_ims\"]:\n",
    "            m2 = re.match(r'^图\\s*([0-9０-９]+)\\s*', line)\n",
    "            if not m2:\n",
    "                continue\n",
    "            n = int(_to_ascii_digits(m2.group(1)))\n",
    "            repo[\"ims_desc\"][n] = _clean_desc(line)\n",
    "\n",
    "    # 若不开 base64/路径，保证字段仍是可序列化的空 dict\n",
    "    if not include_b64:\n",
    "        repo[\"ims_bs64\"] = {}\n",
    "    if not include_path:\n",
    "        repo[\"ims_absp\"] = {}\n",
    "\n",
    "    # 整理顺序\n",
    "    repo[\"ims_desc\"] = {k: repo[\"ims_desc\"][k] for k in sorted(repo[\"ims_desc\"])}\n",
    "    repo[\"ims_absp\"] = {k: repo[\"ims_absp\"][k] for k in sorted(repo[\"ims_absp\"])}\n",
    "    repo[\"ims_bs64\"]  = {k: repo[\"ims_bs64\"].get(k, \"\") for k in sorted(repo[\"ims_desc\"])}\n",
    "\n",
    "    return repo\n",
    "\n",
    "# -------------------- 主类：一次性产出 full_split.md + figs.json --------------------\n",
    "class PatentMdSplit:\n",
    "    \"\"\"\n",
    "    用法：\n",
    "        sp = PatentMdSplit(\n",
    "            mdf=\".../full.md\",\n",
    "            include_b64=True,\n",
    "            include_path=False,\n",
    "            max_b64_mb=6.0,\n",
    "            data_uri=False,\n",
    "            write_meta_raw=True,   # 是否旁存 figs_MetaDict.json\n",
    "        )\n",
    "        out_md, out_figs = sp()   # 返回输出文件路径\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        mdf: str | Path,\n",
    "        *,\n",
    "        include_b64: bool = True,\n",
    "        include_path: bool = False,\n",
    "        safe_read: bool = True,\n",
    "        max_b64_mb: float = 8.0,\n",
    "        data_uri: bool = False,\n",
    "        write_meta_raw: bool = False,\n",
    "    ) -> None:\n",
    "        self.mdf      : Path = Path(mdf)\n",
    "        self.fdir     : Path = self.mdf.parent.resolve()\n",
    "        self.imdir    : Path = self.fdir / \"images\"\n",
    "        # pdf 可选\n",
    "        self.pdff     : Optional[Path] = next(self.fdir.rglob('*_origin.pdf'), None)\n",
    "\n",
    "        # 可选校验\n",
    "        if not self.imdir.is_dir():\n",
    "            # 不强制；有的文档可能无图\n",
    "            pass\n",
    "\n",
    "        self.text: str = self.mdf.read_text(encoding='utf-8', errors=\"ignore\")\n",
    "\n",
    "        # 中间产物（原始 figs 元信息）\n",
    "        self.figs_info: Dict[str, Any] = {}\n",
    "\n",
    "        # 输出控制\n",
    "        self.include_b64 = include_b64\n",
    "        self.include_path = include_path\n",
    "        self.safe_read = safe_read\n",
    "        self.max_b64_mb = max_b64_mb\n",
    "        self.data_uri = data_uri\n",
    "        self.write_meta_raw = write_meta_raw\n",
    "\n",
    "    def __call__(self) -> Tuple[Path, Path]:\n",
    "        return self.pipeline()\n",
    "\n",
    "    # -------------------- pipeline --------------------\n",
    "    def pipeline(self) -> Tuple[Path, Path]:\n",
    "        raw_text = self.text\n",
    "\n",
    "        # 先做一次全局扫描，记录所有图片以及“图片后一行的图号 caption”\n",
    "        all_imgs = list(self._scan_all_images_with_captions(raw_text))\n",
    "\n",
    "        # 1) 摘要图抽取并删除\n",
    "        content = self._extract_abstract_image_and_strip(raw_text)\n",
    "\n",
    "        # 2) 附图说明/附图标记说明抽取，并删除整节\n",
    "        fig_text_items, fig_annos_str, content = self._extract_and_strip_fig_section(content)\n",
    "\n",
    "        if fig_text_items:\n",
    "            self.figs_info[\"lines_ims\"] = fig_text_items  # List[str]\n",
    "        if fig_annos_str:\n",
    "            self.figs_info[\"annos_ims\"] = fig_annos_str   # str\n",
    "\n",
    "        # 3) 文末残留的“图片引用 + 图x” 堆叠删除\n",
    "        content = self._strip_tail_image_blocks(content)\n",
    "\n",
    "        # 4) 依据 “图号→路径” 配对 + “附图说明里的描述”，生成 im_1/im_2…\n",
    "        self._build_im_n_entries(all_imgs, fig_text_items)\n",
    "\n",
    "        # 5) 落盘：纯文本 + figs.json（可选同时写 figs_MetaDict.json）\n",
    "        out_md, out_figs = self._write_down(content)\n",
    "\n",
    "        return out_md, out_figs\n",
    "\n",
    "    # -------------------- 工具函数 --------------------\n",
    "    def _section_span(self, text: str, header_re: re.Pattern, next_header_re: re.Pattern = HEADER_RE) -> Tuple[int, int]:\n",
    "        m = header_re.search(text)\n",
    "        if not m:\n",
    "            return -1, -1\n",
    "        start = m.start()\n",
    "        m2 = next_header_re.search(text, pos=m.end())\n",
    "        end = m2.start() if m2 else len(text)\n",
    "        return start, end\n",
    "\n",
    "    def _scan_all_images_with_captions(self, text: str):\n",
    "        \"\"\"\n",
    "        扫描整篇 md，返回迭代器： {alt, rel, abs, span, fig_no}\n",
    "        - fig_no: 紧跟图片后若出现“图N …”则返回 N（int），否则 None\n",
    "        \"\"\"\n",
    "        for m in IMG_MD_RE.finditer(text):\n",
    "            alt = (m.group(\"alt\") or \"\").strip()\n",
    "            rel = (m.group(\"path\") or \"\").strip()\n",
    "            abs_path = str((self.fdir / rel).resolve())\n",
    "            # 找图片后不远处的“图N …”\n",
    "            lookahead_end = min(len(text), m.end() + 400)\n",
    "            next_chunk = text[m.end():lookahead_end]\n",
    "            cap = re.search(r'^\\s*图\\s*([0-9０-９]+)\\b', next_chunk, re.MULTILINE)\n",
    "            fig_no = None\n",
    "            if cap:\n",
    "                num_str = cap.group(1)\n",
    "                try:\n",
    "                    fig_no = int(self._to_halfwidth_digits(num_str))\n",
    "                except Exception:\n",
    "                    fig_no = None\n",
    "            yield {\n",
    "                \"alt\": alt,\n",
    "                \"rel\": rel,\n",
    "                \"abs\": abs_path,\n",
    "                \"span\": (m.start(), m.end()),\n",
    "                \"fig_no\": fig_no,\n",
    "            }\n",
    "\n",
    "    def _extract_abstract_image_and_strip(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        在“摘要”段落内寻找第一张图片作为摘要图：\n",
    "          - figs_info[\"im_abs\"] = [\"摘要图\", abs_path]\n",
    "          - 删除该图片引用行\n",
    "        \"\"\"\n",
    "        s, e = self._section_span(text, ABSTRACT_HEADER_RE)\n",
    "        if s == -1:\n",
    "            return text\n",
    "\n",
    "        sub = text[s:e]\n",
    "        img = IMG_MD_RE.search(sub)\n",
    "        if not img:\n",
    "            return text\n",
    "\n",
    "        rel = img.group(\"path\").strip()\n",
    "        abs_path = str((self.fdir / rel).resolve())\n",
    "        self.figs_info[\"im_abs\"] = [\"摘要图\", abs_path]\n",
    "\n",
    "        # 删除图片这一整行\n",
    "        line_start = text.rfind(\"\\n\", 0, s + img.start()) + 1\n",
    "        line_end = text.find(\"\\n\", s + img.end())\n",
    "        if line_end == -1:\n",
    "            line_end = len(text)\n",
    "        new_text = text[:line_start] + text[line_end + 1:]\n",
    "        return new_text\n",
    "\n",
    "    def _extract_and_strip_fig_section(self, text: str) -> Tuple[List[str], str, str]:\n",
    "        \"\"\"\n",
    "        提取《附图说明》整节：\n",
    "          - text_ims: [\"图1为xxx\", \"图2是xxx\", ...]\n",
    "          - fig_annos_str: 以“最后一条图描述”为锚点，截其后的“图中标记说明”，做轻度美化\n",
    "        然后把该整节从 md 中删除。\n",
    "        \"\"\"\n",
    "        s, e = self._section_span(text, FIGDESC_HEADER_RE)\n",
    "        if s == -1:\n",
    "            return [], \"\", text\n",
    "\n",
    "        section = text[s:e]\n",
    "\n",
    "        # 去除 [0017] 之类编号以降低干扰（clean 用于提“图n为/是…”；原始 section 保留给锚点匹配）\n",
    "        clean = CN_INDEX_TAG_RE.sub(\" \", section)\n",
    "        clean = re.sub(r'^\\s*#?\\s*附图说明\\s*', '', clean, flags=re.MULTILINE).strip()\n",
    "        mfirst = re.search(r'图\\s*[0-9０-９]', clean)\n",
    "        if mfirst:\n",
    "            clean = clean[mfirst.start():]\n",
    "\n",
    "        # 1) 图描述行\n",
    "        text_ims: List[str] = []\n",
    "        for seg in re.split(r'[；;。]\\s*', clean):\n",
    "            seg = seg.strip()\n",
    "            if not seg:\n",
    "                continue\n",
    "            m = re.match(r'^图\\s*([0-9０-９]+)\\s*(.*)$', seg)\n",
    "            if m:\n",
    "                n = self._to_halfwidth_digits(m.group(1))\n",
    "                rest = m.group(2).strip(\" ：:为是，,\")\n",
    "                if rest:\n",
    "                    text_ims.append(f\"图{n}{('为' if not rest.startswith(('为', '是', ':', '：')) else '')}{rest}\")\n",
    "                else:\n",
    "                    text_ims.append(f\"图{n}\")\n",
    "\n",
    "        # 2) 以最后一条图描述为锚点，抽“图中标记说明”\n",
    "        fig_annos_str = \"\"\n",
    "        if text_ims:\n",
    "            last_line = text_ims[-1]\n",
    "            mm = re.match(r'^图\\s*([0-9]+)\\s*(.*)$', self._to_halfwidth_digits(last_line))\n",
    "            if mm:\n",
    "                last_no = mm.group(1)\n",
    "                core_desc = (mm.group(2) or \"\")\n",
    "                core_desc = core_desc.lstrip(\"为是：:,， \").strip()\n",
    "                anchor_re = re.compile(\n",
    "                    r'(?:\\[\\s*\\d{3,}\\s*\\]\\s*)?图\\s*' + re.escape(last_no) +\n",
    "                    r'\\s*(?:为|是|:|：)?\\s*' +\n",
    "                    re.escape(core_desc).replace(r'\\ ', r'\\s*') +\n",
    "                    r'[^。；;\\n]*[。；;]?',\n",
    "                    re.S\n",
    "                )\n",
    "                last_match = None\n",
    "                for m in anchor_re.finditer(section):\n",
    "                    last_match = m\n",
    "                anchor_pos = last_match.end() if last_match else None\n",
    "                tail = section[anchor_pos:] if anchor_pos is not None else \"\"\n",
    "                fig_annos_str = self._beautify_annos_str(tail)\n",
    "\n",
    "        # 删除整节《附图说明》\n",
    "        new_text = text[:s] + text[e:]\n",
    "        return text_ims, fig_annos_str, new_text\n",
    "\n",
    "    def _beautify_annos_str(self, s: str) -> str:\n",
    "        \"\"\"轻度美化：去编号、合并空白、统一中英文标点、连字符去空格，迭代收敛。\"\"\"\n",
    "        if not s:\n",
    "            return \"\"\n",
    "        def _pass(x: str) -> str:\n",
    "            x = re.sub(r'\\[\\s*\\d{3,}\\s*\\]', '', x)         # 去 [0031]\n",
    "            x = re.sub(r'[ \\t\\r\\n]+', ' ', x).strip()      # 合并空白\n",
    "            # 统一标点\n",
    "            x = re.sub(r'\\s*[:：]\\s*', '：', x)\n",
    "            x = re.sub(r'\\s*[,，]\\s*', '，', x)\n",
    "            x = re.sub(r'\\s*[;；]\\s*', '；', x)\n",
    "            # 连字符去空格（2- 1 -> 2-1）\n",
    "            x = re.sub(r'(\\d)\\s*-\\s*(\\d)', r'\\1-\\2', x)\n",
    "            # 多余标点收敛\n",
    "            x = re.sub(r'，{2,}', '，', x)\n",
    "            x = re.sub(r'；{2,}', '；', x)\n",
    "            x = x.strip('：，；。 ')\n",
    "            x = x.rstrip('。；;')\n",
    "            return x\n",
    "        prev, cur = None, s\n",
    "        for _ in range(4):\n",
    "            prev, cur = cur, _pass(cur)\n",
    "            if cur == prev:\n",
    "                break\n",
    "        return cur\n",
    "\n",
    "    def _strip_tail_image_blocks(self, text: str) -> str:\n",
    "        \"\"\"移除文末连续的 “图片引用 + （可选）图x说明行” 的堆叠。\"\"\"\n",
    "        tail_re = re.compile(\n",
    "            r'(?:\\s*'\n",
    "            r'!\\[[^\\]]*\\]\\([^)]+\\)\\s*'\n",
    "            r'(?:\\n\\s*图[^\\n]*\\s*)?'\n",
    "            r')+\\s*$',\n",
    "            re.S\n",
    "        )\n",
    "        return tail_re.sub(\"\", text)\n",
    "\n",
    "    def _build_im_n_entries(self, all_imgs: List[Dict[str, Any]], text_ims: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        组合 im_1/im_2…：\n",
    "          - 优先用 “图片后紧邻的图号” 来配对路径\n",
    "          - 其次按出现顺序回退\n",
    "          - 文本描述优先取 text_ims 里的 “图n为…”；没有就用 alt 或“图n”\n",
    "        \"\"\"\n",
    "        # 1) 把摘要图从候选里排除（已经作为 im_abs）\n",
    "        abs_img_path = None\n",
    "        if \"im_abs\" in self.figs_info and isinstance(self.figs_info[\"im_abs\"], list) and len(self.figs_info[\"im_abs\"]) >= 2:\n",
    "            abs_img_path = self.figs_info[\"im_abs\"][1]\n",
    "        candidate_imgs = [it for it in all_imgs if it[\"abs\"] != abs_img_path]\n",
    "\n",
    "        # 2) 解析 text_ims -> n -> 描述（保留原始“图n为…”句式，后续 build_figs_repo 会清洗）\n",
    "        desc_map: Dict[int, str] = {}\n",
    "        for t in text_ims or []:\n",
    "            m = re.match(r'^图\\s*([0-9０-９]+)\\s*(.*)$', t.strip())\n",
    "            if m:\n",
    "                n = int(self._to_halfwidth_digits(m.group(1)))\n",
    "                desc = m.group(2).lstrip(\"：:为是，, \")\n",
    "                desc_map[n] = (\"图%d为%s\" % (n, desc)) if desc else (\"图%d\" % n)\n",
    "\n",
    "        # 3) 先用“图片后紧邻的图号”精确配对\n",
    "        no_to_path: Dict[int, str] = {}\n",
    "        used_idxs = set()\n",
    "        for idx, it in enumerate(candidate_imgs):\n",
    "            if it[\"fig_no\"] is not None:\n",
    "                n = it[\"fig_no\"]\n",
    "                if n not in no_to_path:\n",
    "                    no_to_path[n] = it[\"abs\"]\n",
    "                    used_idxs.add(idx)\n",
    "\n",
    "        # 4) 对没有图号的图片，按顺序补充到还没有路径的“图n”\n",
    "        expected_ns = sorted(desc_map.keys()) if desc_map else list(range(1, len(candidate_imgs) + 1))\n",
    "        rest_imgs = [it for i, it in enumerate(candidate_imgs) if i not in used_idxs]\n",
    "\n",
    "        j = 0\n",
    "        for n in expected_ns:\n",
    "            if n not in no_to_path and j < len(rest_imgs):\n",
    "                no_to_path[n] = rest_imgs[j][\"abs\"]\n",
    "                j += 1\n",
    "\n",
    "        # 5) 根据 no_to_path 填充 figs_info 的 im_n\n",
    "        for n in sorted(no_to_path.keys()):\n",
    "            key = f\"im_{n}\"\n",
    "            desc = desc_map.get(n)\n",
    "            if not desc:\n",
    "                # 退化用 alt / 或者“图n”\n",
    "                alt = \"\"\n",
    "                for it in candidate_imgs:\n",
    "                    if it[\"abs\"] == no_to_path[n]:\n",
    "                        alt = it.get(\"alt\") or \"\"\n",
    "                        break\n",
    "                desc = alt.strip() or f\"图{n}\"\n",
    "            self.figs_info[key] = [desc, no_to_path[n]]\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_halfwidth_digits(s: str) -> str:\n",
    "        return s.translate(str.maketrans(\"０１２３４５６７８９\", \"0123456789\")).strip()\n",
    "\n",
    "    # -------------------- 落盘 --------------------\n",
    "    def _write_down(self, content: str) -> Tuple[Path, Path]:\n",
    "        in_name = Path(self.mdf).stem\n",
    "        out_md = self.fdir / f\"{in_name}_split.md\"\n",
    "        out_md.write_text(content, encoding=\"utf-8\")\n",
    "\n",
    "        # 可选旁存原始 figs_MetaDict.json（排查用）\n",
    "        if self.write_meta_raw:\n",
    "            meta_path = self.fdir / \"figs_MetaDict.json\"\n",
    "            with open(meta_path, \"w\", encoding='utf-8') as fj:\n",
    "                json.dump(self.figs_info, fj, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # 规范化 -> figs.json\n",
    "        repo = build_figs_repo(\n",
    "            self.figs_info,\n",
    "            include_b64=self.include_b64,\n",
    "            include_path=self.include_path,\n",
    "            safe_read=self.safe_read,\n",
    "            max_b64_mb=self.max_b64_mb,\n",
    "            data_uri=self.data_uri,\n",
    "        )\n",
    "        out_figs = self.fdir / \"figs.json\"\n",
    "        with open(out_figs, \"w\", encoding=\"utf-8\") as fo:\n",
    "            json.dump(repo, fo, ensure_ascii=False, indent=2)\n",
    "\n",
    "        return out_md, out_figs\n",
    "\n",
    "\n",
    "# -------------------- 批量运行（可选） --------------------\n",
    "if __name__ == '__main__':\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    root_dir = r\"../.log/SimplePDF\"\n",
    "    tft_mds = list(Path(root_dir).rglob(\"*/full.md\"))\n",
    "    for md in tft_mds:\n",
    "        md = str(md)\n",
    "        sp = PatentMdSplit(\n",
    "            md,\n",
    "            include_b64=False,   # 如需瘦身可改为 False\n",
    "            include_path=True, # 不暴露本地路径时设 False\n",
    "            max_b64_mb=6.0,     # image超过6M就不转base64\n",
    "            data_uri=False,\n",
    "            write_meta_raw=True, #\n",
    "        )\n",
    "        sp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struct   full_split.md \n",
    "\n",
    "\n",
    "# normal markdown\n",
    "\"\"\"  \n",
    "-->\n",
    "# record       # --> metadata  --> for search \n",
    "...\n",
    "abs\n",
    "\n",
    "# claims       # 看似不是很重要的东西  --> may used in answer\n",
    "1. ...\n",
    "2. ...\n",
    "...\n",
    "\n",
    "# mannuals     # 细节     --> add for answer\n",
    "\n",
    "\n",
    "将“专利文本（粗糙 Markdown）”规范化为结构化 Markdown：\n",
    "- 归并“著录信息”（含摘要）\n",
    "- 补齐“权利要求书”一级标题\n",
    "- 归档“说明书”并抽取子段（标题、背景技术、发明/实用新型内容、具体实施方式）\n",
    "- 忽略“附图说明 / 说明书附图”段（按用户要求）\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "CLAIM_LINE_RE       = re.compile(r\"^\\s*[（(]?\\s*\\d+\\s*[)）\\.．、]\\s*\")   # 1. / 1、 / 1) / （1）/ 1．\n",
    "ABS_ANCHOR_RE       = re.compile(r\"^\\s*#?\\s*\\(57\\)\\s*摘要\\s*$\")          # “(57)摘要”行（容错带/不带 #）\n",
    "NAME_54_RE          = re.compile(r\"^\\s*#?\\s*\\(54\\)\\s*(?:发明名称|实用新型名称|名称|题名)\\s*$\")\n",
    "TYPE_UTILITY_RE     = re.compile(r\"\\(12\\).*?实用新型\")\n",
    "TYPE_INVENTION_RE   = re.compile(r\"\\(12\\).*?发明\")\n",
    "H1_RE               = re.compile(r\"^\\s*#\\s+(?P<title>.+?)\\s*$\")\n",
    "ANY_H_RE            = re.compile(r\"^\\s*#+\\s*(?P<title>.+?)\\s*$\")\n",
    "\n",
    "# —— 说明书子段识别（含常见变体/同义标题）——\n",
    "SEC_TECH        = {\"技术领域\"}\n",
    "SEC_BG          = {\"背景技术\"}\n",
    "SEC_CONTENT_INV = {\"发明内容\"}                 # 严格按你要求，仅认“发明内容”\n",
    "SEC_CONTENT_UM  = {\"实用新型内容\"}              # 严格按你要求，仅认“实用新型内容”\n",
    "SEC_IMPL        = {\"具体实施方式\"}\n",
    "SEC_FIGS        = {\"附图说明\", \"说明书附图\"}     # 忽略输出\n",
    "\n",
    "# 也把“裸标题”（没有 # 的行）当作分段/截断锚点\n",
    "PLAIN_HEADINGS = SEC_TECH | SEC_BG | SEC_CONTENT_INV | SEC_CONTENT_UM | SEC_IMPL | SEC_FIGS\n",
    "\n",
    "@dataclass\n",
    "class Pieces:\n",
    "    patent_type   : str                  # 'utility' | 'invention' | 'unknown'\n",
    "    meta_prefix   : List[str]            # 摘要行之前的 (xx) 信息块（已去掉行首#）\n",
    "    abstract_lines: List[str]            # 摘要正文（不含 \"(57) 摘要\" 行）\n",
    "    claim_lines   : List[str]            # 权利要求条款行（整块，含内部空行）\n",
    "    body_rest     : List[str]            # 余下说明书原始行\n",
    "    title_text    : Optional[str]        # 标题\n",
    "    sections      : Dict[str, List[str]] # 说明书分段原文（按识别标题键名收拢）\n",
    "\n",
    "class PatentMdStruct:\n",
    "    \"\"\"\n",
    "    将 full_split.md 重构并写同目录：full_split_struct.md\n",
    "    输出结构为：\n",
    "    # record  著录信息\n",
    "    ...(著录信息行)\n",
    "    (57) 摘要\n",
    "    ...(摘要正文)\n",
    "\n",
    "    # claims 权利要求书\n",
    "    1. ...\n",
    "    2. ...\n",
    "    ...\n",
    "\n",
    "    # manuals 说明书 \n",
    "    标题：\n",
    "       xxx\n",
    "    背景技术：\n",
    "       ...\n",
    "    发明内容：/实用新型内容：\n",
    "       ...\n",
    "    具体实施方式：\n",
    "       ...\n",
    "    \"\"\"\n",
    "    def __init__(self, markdown_file_path: str | Path):\n",
    "        self.src = Path(markdown_file_path)\n",
    "        self.text = self.src.read_text(encoding=\"utf-8\", errors=\"ignore\").replace(\"\\r\\n\", \"\\n\")\n",
    "\n",
    "    def __call__(self) -> Path:\n",
    "        pcs = self._segment(self.text)\n",
    "        md  = self._compose(pcs)\n",
    "        out = self.src.with_name(\"full_split_struct.md\")\n",
    "        out.write_text(md, encoding=\"utf-8\")\n",
    "        return out\n",
    "\n",
    "    # ---------------- segmentation ----------------\n",
    "    def _segment(self, txt: str) -> Pieces:\n",
    "        lines = txt.split(\"\\n\")\n",
    "\n",
    "        # 专利类型（前 60 行粗判）\n",
    "        head60 = \"\\n\".join(lines[:60])\n",
    "        if TYPE_UTILITY_RE.search(head60):\n",
    "            ptype = \"utility\"\n",
    "        elif TYPE_INVENTION_RE.search(head60):\n",
    "            ptype = \"invention\"\n",
    "        else:\n",
    "            ptype = \"unknown\"\n",
    "\n",
    "        # 摘要锚点\n",
    "        abs_idx = None\n",
    "        for i, ln in enumerate(lines):\n",
    "            if ABS_ANCHOR_RE.match(ln.strip()):\n",
    "                abs_idx = i; break\n",
    "\n",
    "        meta_prefix, abstract_lines, claim_lines, body_rest = [], [], [], []\n",
    "\n",
    "        if abs_idx is None:\n",
    "            # 无“(57) 摘要”标题：把开头信息先收为 meta，直到发现权利要求或“说明书段标题/裸标题”\n",
    "            cut = 0\n",
    "            while cut < len(lines) and not CLAIM_LINE_RE.match(lines[cut]) and not self._looks_body_heading_or_plain(lines[cut]):\n",
    "                meta_prefix.append(self._strip_leading_hash(lines[cut])); cut += 1\n",
    "            # 权利要求块（无摘要时，同样按“首个编号行→下一个分节标题（含裸标题）”提取）\n",
    "            c_s, c_e = self._find_claims_block(lines, start=cut)\n",
    "            if c_s is not None:\n",
    "                claim_lines = lines[c_s:c_e]\n",
    "                body_rest   = lines[c_e:]\n",
    "            else:\n",
    "                body_rest   = lines[cut:]\n",
    "        else:\n",
    "            # 著录信息到摘要标题行为止\n",
    "            for ln in lines[:abs_idx]:\n",
    "                meta_prefix.append(self._strip_leading_hash(ln))\n",
    "            # 摘要正文：从摘要行下一行，直到出现权利要求起点或“说明书段标题/裸标题”\n",
    "            j = abs_idx + 1\n",
    "            while j < len(lines) and not CLAIM_LINE_RE.match(lines[j]) and not self._looks_body_heading_or_plain(lines[j]):\n",
    "                abstract_lines.append(lines[j].rstrip()); j += 1\n",
    "            # 权利要求整块：从首个编号行开始，到下一个分节标题（包含裸标题）\n",
    "            c_s, c_e = self._find_claims_block(lines, start=j)\n",
    "            if c_s is not None:\n",
    "                claim_lines = lines[c_s:c_e]\n",
    "                body_rest   = lines[c_e:]\n",
    "            else:\n",
    "                body_rest   = lines[j:]\n",
    "\n",
    "        sections   = self._extract_body_sections(body_rest)\n",
    "        title_text = self._extract_title(lines, sections)\n",
    "\n",
    "        return Pieces(\n",
    "            patent_type=ptype,\n",
    "            meta_prefix=self._trim(meta_prefix),\n",
    "            abstract_lines=self._trim(abstract_lines),\n",
    "            claim_lines=self._trim_trailing_blank(claim_lines),  # 保留内部空行，去掉尾部空行\n",
    "            body_rest=body_rest,\n",
    "            title_text=title_text,\n",
    "            sections=sections,\n",
    "        )\n",
    "\n",
    "    def _find_claims_block(self, lines: List[str], start: int) -> Tuple[Optional[int], Optional[int]]:\n",
    "        \"\"\"\n",
    "        从 start 开始寻找首个权利要求编号行（CLAIM_LINE_RE），\n",
    "        返回 [c_start, c_end) 区间，其中 c_end 为后续遇到的首个“Markdown 标题(#开头) 或 裸标题行(技术领域/背景技术/发明内容/实用新型内容/具体实施方式/附图说明/说明书附图)”。\n",
    "        若未找到编号行，返回 (None, None)。\n",
    "        \"\"\"\n",
    "        n = len(lines)\n",
    "        c_start = None\n",
    "        i = start\n",
    "        while i < n:\n",
    "            if CLAIM_LINE_RE.match(lines[i]):\n",
    "                c_start = i\n",
    "                break\n",
    "            # 如果在遇到编号前先撞到了“分节标题/裸标题”，说明没有权利要求\n",
    "            if self._looks_body_heading_or_plain(lines[i]):\n",
    "                return None, None\n",
    "            i += 1\n",
    "        if c_start is None:\n",
    "            return None, None\n",
    "\n",
    "        # 往后一直吃，直到遇到分节标题/裸标题\n",
    "        j = c_start + 1\n",
    "        while j < n and not self._looks_body_heading_or_plain(lines[j]):\n",
    "            j += 1\n",
    "        return c_start, j\n",
    "\n",
    "    # ---------------- compose ----------------\n",
    "    def _compose(self, p: Pieces) -> str:\n",
    "        out: List[str] = []\n",
    "\n",
    "        # record：著录信息 + 摘要\n",
    "        out.append(\"# 著录信息\")     \n",
    "        out.extend(self._trim(p.meta_prefix))\n",
    "        out.append(\"\")\n",
    "        out.append(\"(57) 摘要\")\n",
    "        out.extend(p.abstract_lines)\n",
    "        out.append(\"\")\n",
    "\n",
    "        # claims：整块原样放入\n",
    "        out.append(\"# 权力要求书\")\n",
    "        out.extend(p.claim_lines)\n",
    "        out.append(\"\")\n",
    "\n",
    "        # manuals：说明书（四小节）\n",
    "        out.append(\"# 说明书\")\n",
    "\n",
    "        # 标题\n",
    "        out.append(\"标题：\")\n",
    "        if p.title_text:\n",
    "            out.append(f\"   {p.title_text}\")\n",
    "        out.append(\"\")\n",
    "\n",
    "        # 背景技术\n",
    "        out.append(\"背景技术：\")\n",
    "        bg = p.sections.get(\"背景技术\", [])\n",
    "        out.extend(bg)\n",
    "        out.append(\"\")\n",
    "\n",
    "        # 发明内容 / 实用新型内容（二选一标题）\n",
    "        content_title, content_lines = self._pick_content_block(p)\n",
    "        out.append(f\"{content_title}：\")\n",
    "        out.extend(content_lines)\n",
    "        out.append(\"\")\n",
    "\n",
    "        # 具体实施方式\n",
    "        out.append(\"具体实施方式：\")\n",
    "        impl = []\n",
    "        for k in SEC_IMPL:\n",
    "            if k in p.sections:\n",
    "                impl = p.sections[k]; break\n",
    "        out.extend(impl)\n",
    "        out.append(\"\")\n",
    "\n",
    "        return \"\\n\".join(out)\n",
    "\n",
    "    # ---------------- helpers ----------------\n",
    "    def _pick_content_block(self, p: Pieces) -> Tuple[str, List[str]]:\n",
    "        if \"发明内容\" in p.sections:\n",
    "            return \"发明内容\", p.sections[\"发明内容\"]\n",
    "        if \"实用新型内容\" in p.sections:\n",
    "            return \"实用新型内容\", p.sections[\"实用新型内容\"]\n",
    "        # 如果二者都没有，则按类型兜底给空段\n",
    "        return (\"发明内容\" if p.patent_type == \"invention\" else \"实用新型内容\"), []\n",
    "\n",
    "    @staticmethod\n",
    "    def _strip_leading_hash(s: str) -> str:\n",
    "        s2 = s.lstrip()\n",
    "        if s2.startswith(\"# \"):  # 只把顶层 # 去掉，保持行文本\n",
    "            return s2[2:].strip()\n",
    "        return s.rstrip()\n",
    "\n",
    "    @staticmethod\n",
    "    def _trim(lines: List[str]) -> List[str]:\n",
    "        i, j = 0, len(lines)\n",
    "        while i < j and not lines[i].strip():\n",
    "            i += 1\n",
    "        while j > i and not lines[j - 1].strip():\n",
    "            j -= 1\n",
    "        return [ln.rstrip() for ln in lines[i:j]]\n",
    "\n",
    "    @staticmethod\n",
    "    def _trim_trailing_blank(lines: List[str]) -> List[str]:\n",
    "        # 保留内部空行，只去掉末尾空白\n",
    "        j = len(lines)\n",
    "        while j > 0 and not lines[j - 1].strip():\n",
    "            j -= 1\n",
    "        return [ln.rstrip() for ln in lines[:j]]\n",
    "\n",
    "    @staticmethod\n",
    "    def _title_clean(t: str) -> str:\n",
    "        return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "    def _extract_title(self, lines: List[str], sections: Dict[str, List[str]]) -> Optional[str]:\n",
    "        # 优先 (54) 名称 下一行非 # 的文本\n",
    "        idx54 = None\n",
    "        for i, ln in enumerate(lines[:200]):\n",
    "            if NAME_54_RE.match(ln):\n",
    "                idx54 = i; break\n",
    "        if idx54 is not None:\n",
    "            j = idx54 + 1\n",
    "            while j < len(lines):\n",
    "                cand = lines[j].strip()\n",
    "                if cand and (not ANY_H_RE.match(cand)):\n",
    "                    return self._title_clean(cand)\n",
    "                j += 1\n",
    "        # 次选：第一个不是通用小节名的一级标题\n",
    "        known = PLAIN_HEADINGS\n",
    "        for ln in lines:\n",
    "            m = H1_RE.match(ln)\n",
    "            if m:\n",
    "                t = m.group(\"title\").strip()\n",
    "                if t not in known and not t.startswith(\"(\"):\n",
    "                    return self._title_clean(t)\n",
    "        # 再兜底：任一不属于已知集合的分节名\n",
    "        for k in sections.keys():\n",
    "            if k not in known:\n",
    "                return self._title_clean(k)\n",
    "        return None\n",
    "\n",
    "    def _looks_body_heading_or_plain(self, line: str) -> bool:\n",
    "        \"\"\"既识别以 # 开头的 Markdown 标题，也识别没有 # 的‘裸标题行’。\"\"\"\n",
    "        s = line.strip()\n",
    "        m = ANY_H_RE.match(s)\n",
    "        if m:\n",
    "            t = m.group(\"title\").strip()\n",
    "            return t in (PLAIN_HEADINGS)\n",
    "        # 裸标题：整行等于这些关键字\n",
    "        return s in PLAIN_HEADINGS\n",
    "\n",
    "    def _extract_body_sections(self, body_lines: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        从 body_lines（摘要与权利要求书之后的剩余部分）中，按一级 # 或裸标题切分并抽取：\n",
    "        - 技术领域\n",
    "        - 背景技术\n",
    "        - 发明内容 / 实用新型内容\n",
    "        - 具体实施方式\n",
    "        忽略“附图说明/说明书附图”。\n",
    "        \"\"\"\n",
    "        secs: Dict[str, List[str]] = {}\n",
    "        if not body_lines:\n",
    "            return secs\n",
    "\n",
    "        # 定位各块起点：既支持 \"# 标题\" 也支持裸标题\n",
    "        indices: List[Tuple[str, int]] = []  # (标题, start_line_idx_of_block)\n",
    "        for i, ln in enumerate(body_lines):\n",
    "            s = ln.strip()\n",
    "            m = ANY_H_RE.match(s)\n",
    "            if m:\n",
    "                title = m.group(\"title\").strip()\n",
    "                if title in PLAIN_HEADINGS:\n",
    "                    indices.append((title, i))\n",
    "            elif s in PLAIN_HEADINGS:\n",
    "                indices.append((s, i))\n",
    "\n",
    "        # 若完全没有标题，就把剩余整体作为“具体实施方式”\n",
    "        if not indices:\n",
    "            content = [x.rstrip() for x in body_lines]\n",
    "            content = self._trim(content)\n",
    "            if content:\n",
    "                secs[\"具体实施方式\"] = content\n",
    "            return secs\n",
    "\n",
    "        # 收尾标记\n",
    "        indices.append((\"#END#\", len(body_lines)))\n",
    "\n",
    "        # 提取各段\n",
    "        for (title, s), (_, e) in zip(indices, indices[1:]):\n",
    "            if title in SEC_FIGS:\n",
    "                continue  # 忽略附图说明类\n",
    "            content = [ln.rstrip() for ln in body_lines[s + 1:e]]\n",
    "            content = self._trim(content)\n",
    "            if content:\n",
    "                secs[title] = content\n",
    "\n",
    "        return secs    \n",
    "    \n",
    "# ---- 示例运行（可注释）----\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "\n",
    "    root_dir = Path.cwd().parent / \"./.log\" / \"SimplePDF\"\n",
    "    # print(str(root_dir))\n",
    "    tft_mds = list(Path(root_dir).rglob(\"full_split.md\"))\n",
    "    for md in tqdm(tft_mds):\n",
    "        demo = str(md)\n",
    "        outp = PatentMdStruct(demo)()\n",
    "        print(\"写入：\", outp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化一下 figs.json\n",
    "\n",
    "import re\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "import json \n",
    "\n",
    "def build_figs_repo(\n",
    "    figs: Dict[str, Any],\n",
    "    include_b64: bool = True,          # 默认仅存 base64（更适合入库）\n",
    "    include_path: bool = True,        # 是否保存本地路径  \n",
    "    safe_read: bool = True,            # 读文件前做存在性检查\n",
    "    max_b64_mb: float = 5.0,           # 超过该体积(单图)则不转 base64\n",
    "    data_uri: bool = False,            # base64 是否加 data URI 前缀\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    将原始 figs_MetaDict.json 规范化为：\n",
    "    {\n",
    "        \"im_abs\": [Path|None, str] | None,     # 摘要图：[路径或None, base64或\"\" ]；无摘要图则 None\n",
    "        \"ims_desc\": {int: str},                # 图号 -> 纯描述（去掉“图n为/是/：”前缀）\n",
    "        \"ims_absp\": {int: Path},               # 图号 -> 路径（只有当 include_path=True 才填）\n",
    "        \"ims_bs64\": {int: str},                # 图号 -> base64（只有当 include_b64=True 才填）\n",
    "        \"ims_annos\": str,                      # 附图标记说明（轻度美化）\n",
    "    }\n",
    "    \"\"\"\n",
    "    # -------------------- 工具 --------------------\n",
    "    def _to_halfwidth_digits(s: str) -> str:\n",
    "        return re.sub(r'[０-９]', lambda m: str(ord(m.group(0)) - 65248), s)\n",
    "\n",
    "    def _parse_combo_descs(text: str) -> Dict[int, str]:\n",
    "        \"\"\"支持一行中出现多图：'图10…图11…' -> {10:'…', 11:'…'}\"\"\"\n",
    "        if not text:\n",
    "            return {}\n",
    "        norm = _to_halfwidth_digits(text)\n",
    "        hits = list(re.finditer(r'图\\s*([0-9]{1,3})', norm))\n",
    "        out: Dict[int, str] = {}\n",
    "        for i, m in enumerate(hits):\n",
    "            n = int(m.group(1))\n",
    "            start = m.start()\n",
    "            end = hits[i + 1].start() if i + 1 < len(hits) else len(norm)\n",
    "            chunk = norm[start:end].strip()\n",
    "            prefix = rf'^图\\s*{n}\\s*(?:[:：]?\\s*)?(?:为|是)?\\s*'\n",
    "            desc = re.sub(prefix, '', chunk).strip(' ：:，,；;.。 \\n\\t')\n",
    "            out[n] = desc\n",
    "        return out\n",
    "\n",
    "    def _pick_better(a: Optional[str], b: Optional[str]) -> str:\n",
    "        a = (a or '').strip(); b = (b or '').strip()\n",
    "        if not a: return b\n",
    "        if not b: return a\n",
    "        return b if len(b) >= len(a) else a\n",
    "\n",
    "    def _mime_from_suffix(p: Path) -> str:\n",
    "        ext = p.suffix.lower()\n",
    "        if ext in {\".jpg\", \".jpeg\"}: return \"image/jpeg\"\n",
    "        if ext in {\".png\"}: return \"image/png\"\n",
    "        if ext in {\".gif\"}: return \"image/gif\"\n",
    "        if ext in {\".webp\"}: return \"image/webp\"\n",
    "        return \"application/octet-stream\"\n",
    "\n",
    "    def _file_to_b64(p: Path) -> str:\n",
    "        try:\n",
    "            if max_b64_mb is not None:\n",
    "                if p.exists() and p.is_file() and p.stat().st_size > max_b64_mb * 1024 * 1024:\n",
    "                    return \"\"\n",
    "            with open(p, \"rb\") as f:\n",
    "                raw = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "            return f\"data:{_mime_from_suffix(p)};base64,{raw}\" if data_uri else raw\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    def _beautify_annos_str(s: str) -> str:\n",
    "        if not s: return \"\"\n",
    "        s = s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        s = re.sub(r\"\\s+\", \" \", s)\n",
    "        s = s.replace(\":\", \"：\").replace(\";\", \"；\").replace(\",\", \"，\")\n",
    "        return s.strip(\" ；；。.\")\n",
    "\n",
    "    # -------------------- 容器 --------------------\n",
    "    repo: Dict[str, Any] = {\n",
    "        \"im_abs\": None,\n",
    "        \"ims_desc\": {},\n",
    "        \"ims_absp\": {},\n",
    "        \"ims_bs64\": {},\n",
    "        \"ims_annos\": \"\",\n",
    "    }\n",
    "\n",
    "    # -------------------- 摘要图 -> [Path|None, b64|\"\" ] --------------------\n",
    "    im_abs_val = figs.get(\"im_abs\")\n",
    "    if isinstance(im_abs_val, list) and len(im_abs_val) >= 2:\n",
    "        abs_path = Path(im_abs_val[1])\n",
    "        path_ok = (not safe_read) or abs_path.exists()\n",
    "        abs_b64 = _file_to_b64(abs_path) if (include_b64 and path_ok) else \"\"\n",
    "        repo[\"im_abs\"] = [abs_path if (include_path and path_ok) else None, abs_b64]\n",
    "\n",
    "    # -------------------- 先收集所有路径（可选） --------------------\n",
    "    im_key_pat = re.compile(r\"^im_(\\d+)$\")\n",
    "    for k, v in figs.items():\n",
    "        m = im_key_pat.match(k)\n",
    "        if not m or not (isinstance(v, list) and len(v) >= 2):\n",
    "            continue\n",
    "        n = int(m.group(1))\n",
    "        p = Path(v[1])\n",
    "        if include_path:\n",
    "            if (not safe_read) or p.exists():\n",
    "                repo[\"ims_absp\"][n] = p\n",
    "\n",
    "    # -------------------- 汇聚描述（lines_ims + 每个 im_n 的标题） --------------------\n",
    "    desc_map: Dict[int, str] = {}\n",
    "    for line in figs.get(\"lines_ims\", []) or []:\n",
    "        for n, desc in _parse_combo_descs(line).items():\n",
    "            desc_map[n] = _pick_better(desc_map.get(n), desc)\n",
    "\n",
    "    for k, v in figs.items():\n",
    "        m = im_key_pat.match(k)\n",
    "        if m and isinstance(v, list) and v:\n",
    "            raw_title = str(v[0])\n",
    "            for n, desc in _parse_combo_descs(raw_title).items():\n",
    "                desc_map[n] = _pick_better(desc_map.get(n), desc)\n",
    "\n",
    "    # 保证与已有图号对齐\n",
    "    known_ns = set(int(m.group(1)) for k in figs for m in [im_key_pat.match(k)] if m)\n",
    "    for n in known_ns:\n",
    "        desc_map.setdefault(n, \"\")\n",
    "\n",
    "    repo[\"ims_desc\"] = {int(k): v for k, v in sorted(desc_map.items(), key=lambda x: int(x[0]))}\n",
    "\n",
    "    # -------------------- base64（可选） --------------------\n",
    "    if include_b64:\n",
    "        # 优先从路径生成；如果没存路径也没关系，我们仍按 figs 源路径读取\n",
    "        for k, v in figs.items():\n",
    "            m = im_key_pat.match(k)\n",
    "            if not m or not (isinstance(v, list) and len(v) >= 2):\n",
    "                continue\n",
    "            n = int(m.group(1))\n",
    "            p = Path(v[1])\n",
    "            if (not safe_read) or p.exists():\n",
    "                repo[\"ims_bs64\"][n] = _file_to_b64(p)\n",
    "\n",
    "    # -------------------- 附图标记说明 --------------------\n",
    "    repo[\"ims_annos\"] = _beautify_annos_str(figs.get(\"annos_ims\", \"\"))\n",
    "\n",
    "    return repo\n",
    "\n",
    "    \n",
    "\n",
    "root_dir = r\"..\\.log\\SimplePDF\"\n",
    "\n",
    "tgt_figs = next(Path(root_dir).rglob(\"figs_MetaDict.json\"), None)\n",
    "\n",
    "new_figs = str(tgt_figs)[:-14] + \".json\"\n",
    "# print(new_figs)    # ok\n",
    "\n",
    "with open(tgt_figs, \"r\", encoding='utf-8') as fig:\n",
    "    figs = json.load(fig)\n",
    "    \n",
    "print(build_figs_repo(figs))\n",
    "\n",
    "  \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
