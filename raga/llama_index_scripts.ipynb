{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c45b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0c1240f00b48f3a24fea03d8c6f58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# agents.ipynb\n",
    "\"\"\"   \n",
    "#### AgentWorkflowÁöÑÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü\n",
    "# AgentWorkflow Âçï‰∏™Êô∫ËÉΩ‰Ωì„ÄÅÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü„ÄÇ Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü‰∏≠Â§ö‰∏™Êô∫ËÉΩ‰ΩìÂçè‰ΩúÂÆåÊàê‰ªªÂä°ÔºåÂπ∂Âú®ÈúÄË¶ÅÊó∂Â∞ÜÊéßÂà∂ÊùÉ‰∫íÁõ∏Áßª‰∫§\n",
    "# - ResearchAgent  : ÂÆÉÂ∞ÜÊêúÁ¥¢ÁΩëÁªú‰∏ÄÊü•ÊâæÁªôÂÆö‰∏ªÈ¢òÁöÑ‰ø°ÊÅØ\n",
    "# - WriteAgent     : Â∞ÜÁî®ResearchAgentÊ£ÄÁ¥¢Âà∞ÁöÑ‰ø°ÊÅØÊù•Êí∞ÂÜôÊä•Âëä\n",
    "# - ReviewAgent    : Â∞ÜÂÆ°Êü•Êä•ÂëäÂπ∂Êèê‰æõÂèçÈ¶à\n",
    "## ÈúÄË¶ÅÁî®Âà∞ÁöÑÂ∑•ÂÖ∑\n",
    "# web_searchÂ∑•ÂÖ∑Ôºå  Tavily\n",
    "# record_notesÂ∑•ÂÖ∑ÔºåÂ∞ÜÁΩëÁªúÊêúÁ¥¢ÈÅìÂæ∑Á†îÁ©∂‰øùÂ≠òÂà∞Áä∂ÊÄÅ‰∏≠ÔºàAgentWorkflow‰ΩøÁî®‰∏Ä‰∏™Âêç‰∏∫stateÁöÑContextÂèòÈáèÔºâÔºåÁÑ∂ÂêéÂÖ∂‰ªñÂ∑•ÂÖ∑Â∞±ÂèØ‰ª•‰ΩøÁî®ÂÆÉ\n",
    "# write_repotÂ∑•ÂÖ∑Ôºå‰ΩøÁî®ResearchAgentÊ£ÄÁ¥¢Âà∞ÁöÑ‰ø°ÊÅØÊí∞ÂÜôÊä•Âëä\n",
    "# review_reportÂ∑•ÂÖ∑ÔºåÂÆ°Êü•Êä•ÂëäÂíåÊèê‰æõÂèçÈ¶à\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"   \n",
    "# HuggingFaceLLM ‰∏çÊîØÊåÅÂáΩÊï∞Ë∞ÉÁî®/Â∑•ÂÖ∑ÈÄâÊã©   ËÆ∏Â§öÊú¨Âú∞Â∞èÊ®°ÂûãÈÉΩ‰∏çÊîØÊåÅÂáΩÊï∞Ë∞ÉÁî®„ÄÅÂ∑•ÂÖ∑ÊîØÊåÅÔºå\n",
    "\n",
    "ÊÉ≥Áî®Êú¨Âú∞/Á¶ªÁ∫øÊ®°ÂûãÔºå‰ΩÜÂèàË¶ÅÂ§öÊô∫ËÉΩ‰Ωì‰∏éÂ∑•ÂÖ∑Ë∞ÉÁî®ÔºåÊúâ‰∏§Êù°Ë∑ØÔºö\n",
    "  1. Âú®Êú¨Âú∞Ê®°Âûã‰∏äÂÜçÂ•ó‰∏ÄÂ±ÇÂåÖË£ÖÂô®Ôºà       -- ÁÆÄÂçïÊñπÊ≥ïÔºå \"Êô∫ËÉΩ‰Ωì\"  Ê®°ÂûãËá™Â∑±ÂÜ≥ÂÆöÊòØÂê¶‰ΩøÁî®Â∑•ÂÖ∑/ÂáΩÊï∞„ÄÅÁÑ∂ÂêéÊú¨Âú∞Êú∫Âô®Ë∞ÉÁî®Â∑•ÂÖ∑/ÂáΩÊï∞\n",
    "- Ë∑ë‰∏Ä‰∏™ OpenAI-ÂÖºÂÆπÁΩëÂÖ≥ÔºàÂ¶Ç vLLM + OpenAI Êé•Âè£„ÄÅLiteLLM Á≠âÔºâÔºåÊääÊú¨Âú∞Ê®°Âûã‚ÄúÊåÇÊàê‚Äù OpenAI-style APIÔºåÂÜçÁî® OpenAI Â∞ÅË£ÖÔºõ\n",
    "  2. Ê®°ÂûãÂè™Ë¥üË¥£ÁîüÊàêÊñáÊú¨Ôºå‰∏çË¥üË¥£ÈÄâÂ∑•ÂÖ∑   --Â§çÊùÇÊñπÊ≥ï\n",
    "- ÊîæÂºÉ‚ÄúÁî±Ê®°ÂûãËá™Â∑±ÂÜ≥ÂÆö‰ΩïÊó∂Ë∞ÉÂ∑•ÂÖ∑‚ÄùÔºåÊîπ‰∏∫Â∑•‰ΩúÊµÅÊòæÂºèÁºñÊéíÔºöÁî±‰Ω†Âú® Python ‰∏≠ÂÜ≥ÂÆöÂÖàÊêú‚ÜíÂÜçËÆ∞Á¨îËÆ∞‚ÜíÂÜçÂÜô‚ÜíÂÜçÂÆ°ÔºàÊ®°ÂûãÂè™Ë¥üË¥£ÁîüÊàêÊñáÊú¨Ôºå‰∏çË¥üË¥£ÈÄâÂ∑•ÂÖ∑Ôºâ„ÄÇ\n",
    "\"\"\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from llama_index.core.agent.workflow import AgentWorkflow \n",
    "from llama_index.core.workflow import Context \n",
    "from llama_index.core.agent.workflow import (\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    ")\n",
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent \n",
    "import os \n",
    "\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM \n",
    "llm = HuggingFaceLLM(\n",
    "    model_name     = r\"Qwen/Qwen3-1.7B\",\n",
    "    tokenizer_name = r\"Qwen/Qwen3-1.7B\",\n",
    "    context_window = 3900,  \n",
    "    max_new_tokens = 640,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 30, \"top_p\": 0.95},\n",
    "    device_map     ='cpu' \n",
    ")\n",
    "# HuggingFaceLLM ‰∏çÊîØÊåÅÂáΩÊï∞Ë∞ÉÁî®/Â∑•ÂÖ∑ÈÄâÊã©\n",
    "\n",
    "tavily_tool = TavilyToolSpec(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "search_web = tavily_tool.to_tool_list()[0]\n",
    "\n",
    "# ---- Â∑•ÂÖ∑ÂáΩÊï∞   \n",
    "async def record_notes(ctx: Context, notes: str, notes_title: str) -> str:\n",
    "    \"\"\" useful for recording notes on a gaven topic.\"\"\"\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    if \"research_notes\" not in current_state:\n",
    "        current_state[\"research_notes\"] = {}\n",
    "    current_state[\"research_notes\"][notes_title] = notes\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    return \"Notes recorded.\"\n",
    "\n",
    "async def write_report(ctx:Context, report_content:str) -> str:\n",
    "    \"\"\" useful write a report on a gaven topic.\"\"\"\n",
    "    current_state = ctx.store.get(\"state\")\n",
    "    current_state[\"report_content\"] = report_content\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    return \"Report written\"\n",
    "    \n",
    "async def review_report(ctx:Context, review:str) -> str:\n",
    "    \"\"\"useful for reviewing a report and providing feedbacks\"\"\"\n",
    "    current_state = ctx.store.get(\"state\")\n",
    "    current_state[\"review\"] = review\n",
    "    await ctx.store.set([\"state\"],current_state)\n",
    "    return \"Report reviewed\" \n",
    "\n",
    "# ------------- agent\n",
    "research_agent = FunctionAgent(\n",
    "    name=\"ResearchAgent\",\n",
    "    description=\"Useful for searching the web for information on a given topic and recording notes on the topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ResearchAgent that can search the web for information on a given topic and record notes on the topic. \"\n",
    "        \"Once notes are recorded and you are satisfied, you should hand off control to the WriteAgent to write a report on the topic.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[search_web, record_notes],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "write_agent = FunctionAgent(\n",
    "    name=\"WriteAgent\",\n",
    "    description=\"Useful for writing a report on a given topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the WriteAgent that can write a report on a given topic. \"\n",
    "        \"Your report should be in a markdown format. The content should be grounded in the research notes. \"\n",
    "        \"Once the report is written, you should get feedback at least once from the ReviewAgent.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[write_report],\n",
    "    can_handoff_to=[\"ReviewAgent\", \"ResearchAgent\"],\n",
    ")\n",
    "\n",
    "review_agent = FunctionAgent(\n",
    "    name=\"ReviewAgent\",\n",
    "    description=\"Useful for reviewing a report and providing feedback.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ReviewAgent that can review a report and provide feedback. \"\n",
    "        \"Your feedback should either approve the current report or request changes for the WriteAgent to implement.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[review_report],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "agent_workflow = AgentWorkflow(\n",
    "    agents=[research_agent, write_agent, review_agent],\n",
    "    root_agent=research_agent.name,\n",
    "    initial_state={\n",
    "        \"research_notes\": {},\n",
    "        \"report_content\": \"Not written yet.\",\n",
    "        \"review\": \"Review required.\",\n",
    "    },\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    handler = agent_workflow.run(user_msg=\"\"\"\n",
    "        Write me a report on the history of the web. Briefly describe the history \n",
    "        of the world wide web, including the development of the internet and the \n",
    "        development of the web, including 21st century developments.\n",
    "    \"\"\")\n",
    "    \n",
    "    current_agent = None \n",
    "    current_tool_calls = \"\" \n",
    "    async for event in handler.stream_events():\n",
    "        if (\n",
    "            hasattr(event, \"current_agent_name\")\n",
    "            and event.current_agent_name != current_agent\n",
    "        ):\n",
    "            current_agent = event.current_agent_name\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"ü§ñ Agent: {current_agent}\")\n",
    "            print(f\"{'='*50}\\n\")\n",
    "        elif isinstance(event, AgentOutput):\n",
    "            if event.response.content:\n",
    "                print(\"üì§ Output:\", event.response.content)\n",
    "            if event.tool_calls:\n",
    "                print(\n",
    "                    \"üõ†Ô∏è  Planning to use tools:\",\n",
    "                    [call.tool_name for call in event.tool_calls],\n",
    "                )\n",
    "        elif isinstance(event, ToolCallResult):\n",
    "            print(f\"üîß Tool Result ({event.tool_name}):\")\n",
    "            print(f\"  Arguments: {event.tool_kwargs}\")\n",
    "            print(f\"  Output: {event.tool_output}\")\n",
    "        elif isinstance(event, ToolCall):\n",
    "            print(f\"üî® Calling Tool: {event.tool_name}\")\n",
    "            print(f\"  With arguments: {event.tool_kwargs}\")\n",
    "\n",
    "\"\"\"   .py\n",
    "if __name__ == '__main__':\n",
    "    import asyncio \n",
    "    asyncio.run(main())\n",
    "\"\"\"\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f0051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3319b4baaa30474e81ebdbeff9eb7e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research done.\n",
      "‚úÖ Draft written.\n",
      "‚úÖ Review: approved=False\n",
      "‚úÖ Final approved=False\n",
      "\n",
      "================================================================================\n",
      "# ÊúÄÁªàÊä•ÂëäÔºàÊà™Êñ≠Â±ïÁ§∫Ôºâ\n",
      "\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶ÂêàË¶ÅÊ±ÇÔºå‰∏çÂåÖÂê´‰ªª‰ΩïÈ¢ùÂ§ñ‰ø°ÊÅØ„ÄÇ\n",
      "### ËØ∑Á°Æ‰øùËæìÂá∫ÁöÑÊØè‰∏™Ë¶ÅÁÇπÈÉΩÁ¨¶Âêà\n",
      "\n",
      "# ÂÆ°Á®øËß£ÊûêÔºö {'approved': False, 'summary': 'The manuscript requires significant revisions to enhance clarity, depth of analysis, and experimental details.', 'changes': ['Add detailed experimental procedures for the key methodologies used in the study.', 'Improve the statistical analysis by including more robust methods and reporting effect sizes.', 'Expand the discussion section to address potential limitations and alternative interpretations of the results.', 'Clarify the significance of the findings in the context of existing literature.', 'Refine the figure legends and add additional figures to support the main conclusions.']}\n"
     ]
    }
   ],
   "source": [
    "# ÊòæÁ§∫Â∑•‰ΩúÊµÅÂÆâÊéíÔºå Âõ†‰∏∫Áé∞Âú®ÊàëÁöÑÊú¨Âú∞hf-llm‰∏çÊîØÊåÅÂ∑•ÂÖ∑/ÂáΩÊï∞Ë∞ÉÁî®ÔºàÊó†function-callingÔºâ  -- runs ok  \n",
    "# ### Áº∫ÁÇπÔºö ‰∏≠Èó¥‰ø°ÊÅØÂ§çÁî®ÁöÑ‰ª£Á†ÅÈÄªËæë‰∏çÂ•ΩÂÜôÔºåÊâÄ‰ª•ËøòÊòØÁî®llama-indexÔºàContextÔºâ\n",
    "# Êú¨Âú∞hf-llmÂè™ÁîüÊàêÊñáÊú¨ÔºàÈÄöËøáÊèêÁ§∫ËØçÊéßÂà∂ ÁîüÊàêÊñáÊú¨ Ëøô‰∏™Ë°å‰∏∫ÔºâÔºå\n",
    "# ÂÖ∂‰ΩôÁöÑÊàëÊù•\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os, json, re, textwrap, requests\n",
    "\n",
    "# 1) Êú¨Âú∞/Á¶ªÁ∫ø LLMÔºà‰∏çÈúÄË¶ÅÂ∑•ÂÖ∑Ë∞ÉÁî®ÂçèËÆÆÔºâ\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name     = r\"Qwen/Qwen3-1.7B\",\n",
    "    tokenizer_name = r\"Qwen/Qwen3-1.7B\",\n",
    "    context_window = 3900,\n",
    "    max_new_tokens = 640,\n",
    "    generate_kwargs={\"temperature\": 0.5, \"top_k\": 30, \"top_p\": 0.95},\n",
    "    device_map     = \"cpu\",\n",
    ")\n",
    "\n",
    "# 2) Tavily ÊêúÁ¥¢ÔºàÁõ¥Êé• RESTÔºõ‰∏ç‰æùËµñ LlamaIndex ÁöÑ ToolÔºâ\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "def tavily_search(query: str, max_results: int = 6, depth: str = \"advanced\"):\n",
    "    \"\"\"ÊòæÂºèË∞ÉÁî® Tavily ÁöÑ REST API„ÄÇ\"\"\"\n",
    "    url = \"https://api.tavily.com/search\"\n",
    "    payload = {\n",
    "        \"api_key\": TAVILY_API_KEY,\n",
    "        \"query\": query,\n",
    "        \"search_depth\": depth,           # \"basic\" / \"advanced\"\n",
    "        \"include_images\": False,\n",
    "        \"include_answer\": False,\n",
    "        \"max_results\": max_results,\n",
    "    }\n",
    "    r = requests.post(url, json=payload, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    # ÊúüÊúõ data[\"results\"] ÊòØ [{title, url, content, score?}, ...]\n",
    "    return data.get(\"results\", [])\n",
    "\n",
    "def _trim(s: str, n=8000):\n",
    "    return s if len(s) <= n else (s[:n] + \" ...[truncated]\")\n",
    "\n",
    "# --------------------- ÊòæÂºè‚ÄúÂ∑•‰ΩúÊµÅ‚ÄùÊ≠•È™§ ---------------------\n",
    "\n",
    "def step_research(topic: str) -> dict:\n",
    "    \"\"\"Step-1: ÊêúÁ¥¢ + ÁîüÊàêÁªìÊûÑÂåñÁ¨îËÆ∞ÔºàÊòæÂºèË∞ÉÁî® Tavily ‰∏éÊú¨Âú∞LLMÔºâ\"\"\"\n",
    "    results = tavily_search(topic, max_results=6, depth=\"advanced\")\n",
    "    sources_md = \"\\n\".join(\n",
    "        f\"- [{it.get('title','(no title)')}]({it.get('url','')}) ‚Äî {it.get('content','')[:240].replace('\\n', ' ')}\"\n",
    "        for it in results\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "‰Ω†ÊòØÁ†îÁ©∂Âä©ÁêÜ„ÄÇÂü∫‰∫é‰∏ãÂàóÊ£ÄÁ¥¢Âà∞ÁöÑËµÑÊñôÔºå‰∏∫‚Äú{topic}‚ÄùÁîüÊàê‰∏çË∂ÖËøá 10 Êù°ÁöÑË¶ÅÁÇπÂºèÁ†îÁ©∂Á¨îËÆ∞ÔºàMarkdownÔºâ„ÄÇ\n",
    "Ë¶ÅÊ±ÇÔºö\n",
    "- Ë¶ÜÁõñÂÖ≥ÈîÆÊó∂Èó¥Á∫ø/ÈáåÁ®ãÁ¢ë/Ê†∏ÂøÉ‰∫∫Áâ©ÊàñÊú∫ÊûÑ\n",
    "- Á™ÅÂá∫ 21 ‰∏ñÁ∫™ÁöÑÂèëÂ±ïÔºàËã•Áõ∏ÂÖ≥Ôºâ\n",
    "- Â∞ΩÈáèÂºïÁî®Êù•Ê∫êÔºà‰ª• [ÁºñÂè∑] ÂΩ¢ÂºèÂØπÁÖß‰∏ãÊñπ‚ÄúËµÑÊñôÂàóË°®‚ÄùÂ∫èÂè∑Ôºâ\n",
    "\n",
    "ËµÑÊñôÂàóË°®ÔºàÊåâÈ°∫Â∫èÊ†áÂè∑ÔºâÔºö\n",
    "{sources_md}\n",
    "\n",
    "ËØ∑ËæìÂá∫Ôºö\n",
    "### Á¨îËÆ∞\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n",
    "### ÂºïÁî®Êù•Ê∫ê\n",
    "- [1] Ê†áÈ¢òÔºàÈìæÊé•Ôºâ\n",
    "- [2] ...\n",
    "\"\"\"\n",
    "    notes = llm.complete(prompt).text\n",
    "    state = {\n",
    "        \"topic\": topic,\n",
    "        \"search_results\": results,\n",
    "        \"notes_md\": notes,\n",
    "        \"sources_md\": sources_md,\n",
    "    }\n",
    "    return state\n",
    "\n",
    "def step_write_report(state: dict) -> dict:\n",
    "    \"\"\"Step-2: ÂÜôÊä•ÂëäÔºàÊòæÂºèÊää‰∏ä‰∏ÄÊ≠•ÁöÑÁ¨îËÆ∞‰º†ÂÖ• LLMÔºâ\"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    notes_md = state[\"notes_md\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "‰Ω†ÊòØ‰∏ÄÂêçÊäÄÊúØÂÜô‰ΩúËÄÖ„ÄÇËØ∑Âü∫‰∫é‰∏ãÊñπ‚ÄúÁ†îÁ©∂Á¨îËÆ∞‚Äù‰∏∫‰∏ªÈ¢ò‚Äú{topic}‚ÄùÊí∞ÂÜô‰∏ÄÁØá**ÁªìÊûÑÂåñ Markdown Êä•Âëä**„ÄÇ\n",
    "Ë¶ÅÊ±ÇÔºö\n",
    "- ÁªìÊûÑÁ§∫‰æãÔºö# Ê¶ÇËßà / ## Êó©ÊúüÂèëÂ±ï / ## 1990s / ## 2000s / ## 2010s-2020s / ## ÂèÇËÄÉËµÑÊñô\n",
    "- ÂÜÖÂÆπÂøÖÈ°ª**Á¥ßÂØÜ‰æùËµñ**Á†îÁ©∂Á¨îËÆ∞Ôºå‰∏çË¶ÅÁºñÈÄ†\n",
    "- ËØ≠Ë®ÄÁÆÄÊ¥ÅÔºåÊÆµËêΩÁü≠Â∞è\n",
    "\n",
    "--- Á†îÁ©∂Á¨îËÆ∞ ---\n",
    "{notes_md}\n",
    "\"\"\"\n",
    "    report_md = llm.complete(prompt).text\n",
    "    state[\"report_md\"] = report_md\n",
    "    return state\n",
    "\n",
    "def _extract_json_block(text: str) -> dict:\n",
    "    \"\"\"‰ªéÊ®°ÂûãËæìÂá∫‰∏≠Â∞ΩÈáèÊèêÂèñ JSONÔºàÁ®≥ÂÅ•Ëß£ÊûêÔºâ\"\"\"\n",
    "    # ÂÖàÊâæ ```json ... ``` ÂåÖË£π\n",
    "    m = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", text, flags=re.S)\n",
    "    if not m:\n",
    "        # ÈÄÄÂåñÔºöÊâæÁ¨¨‰∏Ä‰∏™ { ... } Âùó\n",
    "        m = re.search(r\"(\\{.*\\})\", text, flags=re.S)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(m.group(1))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def step_review(state: dict, strict: bool = False) -> dict:\n",
    "    \"\"\"Step-3: ÂÆ°Á®øÔºàËæìÂá∫ JSONÔºöapproved/changesÔºâ\"\"\"\n",
    "    report_md = state[\"report_md\"]\n",
    "    prompt = f\"\"\"\n",
    "‰Ω†ÊòØÂÆ°Á®ø‰∫∫„ÄÇËØ∑‰ªÖ‰ª• JSON ÊñπÂºèÁªôÂá∫ÂÆ°Á®øÁªìËÆ∫„ÄÇ\n",
    "ËßÑÂàôÔºö\n",
    "- Â≠óÊÆµÔºöapproved (bool), summary (string), changes (string[])\n",
    "- Ëã• approved=falseÔºåËØ∑ÁªôÂá∫ 3-6 Êù°ÂÖ∑‰Ωì‰øÆÊîπÂª∫ËÆÆ\n",
    "- ËæìÂá∫ÂøÖÈ°ªÊîæÂú®‰∏Ä‰∏™ ```json Âùó‰∏≠Ôºå‰∏çË¶ÅÂá∫Áé∞Â§ö‰ΩôÊñáÂ≠ó\n",
    "\n",
    "--- ÂæÖÂÆ°Êä•Âëä ---\n",
    "{_trim(report_md, 7000)}\n",
    "\"\"\"\n",
    "    review_raw = llm.complete(prompt).text\n",
    "    parsed = _extract_json_block(review_raw)\n",
    "    # ÂÆπÈîôÔºöÈªòËÆ§ÈÄöËøá\n",
    "    approved = bool(parsed.get(\"approved\", True))\n",
    "    changes = parsed.get(\"changes\", [])\n",
    "    summary = parsed.get(\"summary\", \"OK\")\n",
    "\n",
    "    state[\"review\"] = {\n",
    "        \"raw\": review_raw,\n",
    "        \"parsed\": parsed,\n",
    "        \"approved\": approved,\n",
    "        \"changes\": changes,\n",
    "        \"summary\": summary,\n",
    "    }\n",
    "    return state\n",
    "\n",
    "def step_revise_if_needed(state: dict, max_rounds: int = 1) -> dict:\n",
    "    \"\"\"ÂèØÈÄâÔºöÊ†πÊçÆÂÆ°Á®øÊÑèËßÅËøõË°å 0~N ËΩÆ‰øÆËÆ¢\"\"\"\n",
    "    rounds = 0\n",
    "    while rounds < max_rounds and not state[\"review\"][\"approved\"]:\n",
    "        changes = state[\"review\"][\"changes\"]\n",
    "        report_md = state[\"report_md\"]\n",
    "        topic = state[\"topic\"]\n",
    "        notes_md = state[\"notes_md\"]\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Ê†πÊçÆ‰ª•‰∏ãÂÆ°Á®øÊÑèËßÅ‰øÆËÆ¢Êä•Âëä„Ää{topic}„Äã„ÄÇÂøÖÈ°ªÈÅµÂæ™ÂÆ°Á®øÊù°ÁõÆÈÄêÊù°‰øÆÊîπÔºö\n",
    "- ÂÆ°Á®øÊÑèËßÅÔºö\n",
    "{json.dumps(changes, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ÈôêÂà∂Ôºö\n",
    "- ‰ªçÈúÄ‰∏•Ê†º‰æùËµñ‚ÄúÁ†îÁ©∂Á¨îËÆ∞‚ÄùÔºå‰∏çË¶ÅÁºñÈÄ†\n",
    "- ‰øùÊåÅ Markdown ÁªìÊûÑÊ∏ÖÊô∞\n",
    "\n",
    "--- Á†îÁ©∂Á¨îËÆ∞ ---\n",
    "{notes_md}\n",
    "\n",
    "--- ÊóßÁâàÊä•Âëä ---\n",
    "{_trim(report_md, 7000)}\n",
    "\"\"\"\n",
    "        new_report = llm.complete(prompt).text\n",
    "        state[\"report_md\"] = new_report\n",
    "        # ÈáçÊñ∞ÂÆ°Á®ø\n",
    "        state = step_review(state)\n",
    "        rounds += 1\n",
    "    return state\n",
    "\n",
    "# --------------------- È°∂Â±Ç orchestrator ---------------------\n",
    "\n",
    "def run_explicit_workflow(user_request: str, revise_rounds: int = 1) -> dict:\n",
    "    # 1) Á†îÁ©∂\n",
    "    state = step_research(user_request)\n",
    "    print(\"‚úÖ Research done.\")\n",
    "\n",
    "    # 2) ÂÜô‰Ωú\n",
    "    state = step_write_report(state)\n",
    "    print(\"‚úÖ Draft written.\")\n",
    "\n",
    "    # 3) ÂÆ°Á®ø\n",
    "    state = step_review(state)\n",
    "    print(f\"‚úÖ Review: approved={state['review']['approved']}\")\n",
    "\n",
    "    # 4) ÈúÄË¶ÅÁöÑËØùÔºå‰øÆËÆ¢Ëã•Âπ≤ËΩÆ\n",
    "    state = step_revise_if_needed(state, max_rounds=revise_rounds)\n",
    "    print(f\"‚úÖ Final approved={state['review']['approved']}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "# --------------------- ËøêË°åÁ§∫‰æã ---------------------\n",
    "if __name__ == \"__main__\":\n",
    "    topic = \"History of the World Wide Web and key 21st-century developments\"\n",
    "    final_state = run_explicit_workflow(topic, revise_rounds=1)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"# ÊúÄÁªàÊä•ÂëäÔºàÊà™Êñ≠Â±ïÁ§∫Ôºâ\\n\")\n",
    "    print(_trim(final_state[\"report_md\"], 4000))\n",
    "    print(\"\\n# ÂÆ°Á®øËß£ÊûêÔºö\", final_state[\"review\"][\"parsed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4a4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecb7c17324c4031b58b8e3031c6efed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "WorkflowConfigurationError",
     "evalue": "At least one Event of type StopEvent must be returned by any step.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWorkflowConfigurationError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     m = re.search(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m```json\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m{\u001b[39m\u001b[33m.*?\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m})\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*```\u001b[39m\u001b[33m\"\u001b[39m, text, flags=re.S) \u001b[38;5;129;01mor\u001b[39;00m re.search(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m{\u001b[39m\u001b[33m.*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m})\u001b[39m\u001b[33m\"\u001b[39m, text, flags=re.S)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(m.group(\u001b[32m1\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m wf = \u001b[43mWorkflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@step\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresearch\u001b[39m(ev: StartEvent) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     40\u001b[39m     topic = ev.input[\u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\developer\\miniconda\\envs\\langchain\\Lib\\site-packages\\workflows\\workflow.py:108\u001b[39m, in \u001b[36mWorkflow.__init__\u001b[39m\u001b[34m(self, timeout, disable_validation, verbose, service_manager, resource_manager, num_concurrent_runs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28mself\u001b[39m._disable_validation = disable_validation\n\u001b[32m    107\u001b[39m \u001b[38;5;28mself\u001b[39m._num_concurrent_runs = num_concurrent_runs\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28mself\u001b[39m._stop_event_class = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_stop_event_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m._start_event_class = \u001b[38;5;28mself\u001b[39m._ensure_start_event_class()\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._sem = (\n\u001b[32m    111\u001b[39m     asyncio.Semaphore(num_concurrent_runs) \u001b[38;5;28;01mif\u001b[39;00m num_concurrent_runs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    112\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\developer\\miniconda\\envs\\langchain\\Lib\\site-packages\\workflows\\workflow.py:167\u001b[39m, in \u001b[36mWorkflow._ensure_stop_event_class\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_found == \u001b[32m0\u001b[39m:\n\u001b[32m    166\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mAt least one Event of type StopEvent must be returned by any step.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WorkflowConfigurationError(msg)\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m num_found > \u001b[32m1\u001b[39m:\n\u001b[32m    169\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly one type of StopEvent is allowed per workflow, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstop_events_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mWorkflowConfigurationError\u001b[39m: At least one Event of type StopEvent must be returned by any step."
     ]
    }
   ],
   "source": [
    "# Áî® LlamaIndex ÁöÑ WorkflowÔºà‰ªçÊòØÊòæÂºèË∑ØÂæÑÔºå‰∏çËÆ©Ê®°ÂûãÊåëÂ∑•ÂÖ∑Ôºâ\n",
    "# explicit_workflow_llamaindex.py  ‚Äî‚Äî ÊòæÂºèÁºñÊéíÔºåÊó† function-calling\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os, json, re, requests\n",
    "from typing import Union\n",
    "\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.workflow import (\n",
    "    Workflow, StartEvent, StopEvent, step, Event\n",
    ")\n",
    "\n",
    "# ================== Âü∫Á°ÄÁªÑ‰ª∂ ==================\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name     = r\"Qwen/Qwen3-1.7B\",\n",
    "    tokenizer_name = r\"Qwen/Qwen3-1.7B\",\n",
    "    context_window = 3900,\n",
    "    max_new_tokens = 640,\n",
    "    generate_kwargs={\"temperature\": 0.5, \"top_k\": 30, \"top_p\": 0.95},\n",
    "    device_map     = \"cpu\",\n",
    ")\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "def tavily_search(query: str, max_results: int = 6):\n",
    "    url = \"https://api.tavily.com/search\"\n",
    "    payload = {\n",
    "        \"api_key\": TAVILY_API_KEY,\n",
    "        \"query\": query,\n",
    "        \"search_depth\": \"advanced\",\n",
    "        \"max_results\": max_results\n",
    "    }\n",
    "    resp = requests.post(url, json=payload, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json().get(\"results\", [])\n",
    "\n",
    "def _extract_json_block(text: str) -> dict:\n",
    "    m = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", text, flags=re.S) or re.search(r\"(\\{.*\\})\", text, flags=re.S)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(m.group(1))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# ================== ‰∫ã‰ª∂Á±ªÂûãÔºàÊòæÂºèÂÆö‰πâÔºâ ==================\n",
    "class ResearchDone(Event):\n",
    "    topic: str\n",
    "    sources_md: str\n",
    "    notes_md: str\n",
    "\n",
    "class DraftWritten(Event):\n",
    "    topic: str\n",
    "    notes_md: str\n",
    "    report_md: str\n",
    "\n",
    "class ReviewApproved(Event):\n",
    "    topic: str\n",
    "    notes_md: str\n",
    "    report_md: str\n",
    "    review: dict  # {\"approved\": True, \"summary\": \"...\", \"changes\": []}\n",
    "\n",
    "class ReviewChangesNeeded(Event):\n",
    "    topic: str\n",
    "    notes_md: str\n",
    "    report_md: str\n",
    "    review: dict  # {\"approved\": False, \"summary\": \"...\", \"changes\": [...]}\n",
    "\n",
    "# ================== Workflow & Steps ==================\n",
    "class wf(Workflow):\n",
    "    # Âõ†‰∏∫ÊòØ‰ªéÂâçÂæÄÂêéÔºåÂçïÁ∫øÔºå ÊâÄ‰ª•‰∏çÁî®Context‰πüÂèØ‰ª•\n",
    "    @step\n",
    "    def research(ev: StartEvent) -> ResearchDone:\n",
    "        topic = ev.input[\"topic\"]\n",
    "        results = tavily_search(topic, max_results=6)\n",
    "        sources_md = \"\\n\".join(\n",
    "            f\"- [{it.get('title','(no title)')}]({it.get('url','')}) ‚Äî {it.get('content','')[:240].replace('\\n',' ')}\"\n",
    "            for it in results\n",
    "        )\n",
    "        prompt = f\"ËØ∑Âü∫‰∫é‰∏ãÂàóËµÑÊñô‰∏∫‚Äú{topic}‚ÄùÁîüÊàê 6-10 Êù°Ë¶ÅÁÇπÂºè Markdown Á¨îËÆ∞Ôºö\\n{sources_md}\"\n",
    "        notes_md = llm.complete(prompt).text\n",
    "        return ResearchDone(topic=topic, sources_md=sources_md, notes_md=notes_md)\n",
    "\n",
    "    @step\n",
    "    def write(ev: ResearchDone) -> DraftWritten:\n",
    "        topic, notes_md = ev.topic, ev.notes_md\n",
    "        prompt = f\"Âü∫‰∫éÁ†îÁ©∂Á¨îËÆ∞‰∏∫‚Äú{topic}‚ÄùÂÜô‰∏ÄÁØáÁªìÊûÑÂåñ Markdown Êä•ÂëäÔºö\\n{notes_md}\"\n",
    "        report_md = llm.complete(prompt).text\n",
    "        return DraftWritten(topic=topic, notes_md=notes_md, report_md=report_md)\n",
    "\n",
    "    @step\n",
    "    def review(ev: DraftWritten) -> Union[ReviewApproved, ReviewChangesNeeded]:\n",
    "        report_md = ev.report_md\n",
    "        prompt = f\"\"\"‰Ω†ÊòØÂÆ°Á®ø‰∫∫Ôºå‰ªÖ‰ª• JSON ÂõûÁ≠îÔºö{{\"approved\": true/false, \"summary\": \"...\", \"changes\": [\"...\"]}}„ÄÇ\n",
    "    Êä•ÂëäÔºö\n",
    "    {report_md}\n",
    "    \"\"\"\n",
    "        parsed = _extract_json_block(llm.complete(prompt).text)\n",
    "        if not parsed:\n",
    "            parsed = {\"approved\": True, \"summary\": \"OK\", \"changes\": []}\n",
    "\n",
    "        if bool(parsed.get(\"approved\", True)):\n",
    "            return ReviewApproved(\n",
    "                topic=ev.topic, notes_md=ev.notes_md, report_md=report_md, review=parsed\n",
    "            )\n",
    "        else:\n",
    "            return ReviewChangesNeeded(\n",
    "                topic=ev.topic, notes_md=ev.notes_md, report_md=report_md, review=parsed\n",
    "            )\n",
    "\n",
    "    @step\n",
    "    def revise(ev: ReviewChangesNeeded) -> DraftWritten:\n",
    "        \"\"\"ÊåâÂÆ°Á®øÊÑèËßÅ‰øÆËÆ¢‰∏ÄËΩÆÂêéÔºåÂõûÂà∞ review„ÄÇ\"\"\"\n",
    "        changes = ev.review.get(\"changes\", [])\n",
    "        prompt = (\n",
    "            \"Ê†πÊçÆ‰ª•‰∏ãÂÆ°Á®øÊÑèËßÅ‰øÆËÆ¢Êä•ÂëäÔºà‰øùÊåÅ Markdown ÁªìÊûÑÔºåÈÄêÊù°ËêΩÂÆûÔºâÔºö\\n\"\n",
    "            f\"{json.dumps(changes, ensure_ascii=False, indent=2)}\\n\"\n",
    "            \"---\\nÊóßÁâàÔºö\\n\"\n",
    "            f\"{ev.report_md}\"\n",
    "        )\n",
    "        new_report = llm.complete(prompt).text\n",
    "        return DraftWritten(topic=ev.topic, notes_md=ev.notes_md, report_md=new_report)\n",
    "\n",
    "    @step\n",
    "    def end(ev: ReviewApproved) -> StopEvent:\n",
    "        \"\"\"ÁªàÊ≠¢ÔºöËøîÂõûÊúÄÁªàÊä•Âëä‰∏éÂÆ°Á®øÁªìÊûú„ÄÇ\"\"\"\n",
    "        return StopEvent(result={\"report_md\": ev.report_md, \"review\": ev.review})\n",
    "\n",
    "\n",
    "# =============== ËøêË°å‰∏éÊâìÂç∞ ===============\n",
    "handler = wf.run(input={\"topic\": \"History of the World Wide Web and 21st-century developments\"})\n",
    "\n",
    "# ÂèØÈÄâÔºöÊâìÂç∞‰∫ã‰ª∂ÊµÅ\n",
    "for ev in handler.stream_events():\n",
    "    name = type(ev).__name__\n",
    "    payload = getattr(ev, \"result\", None)\n",
    "    if payload:\n",
    "        print(f\"[{name}] result keys: {list(payload) if isinstance(payload, dict) else str(payload)[:60]}\")\n",
    "    else:\n",
    "        print(f\"[{name}]\")\n",
    "\n",
    "final = handler.get()  # StopEvent.result\n",
    "print(\"\\n=== FINAL REPORT (snippet) ===\\n\")\n",
    "print(final[\"report_md\"][:2000])\n",
    "print(\"\\n=== REVIEW ===\\n\", json.dumps(final[\"review\"], ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea779dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file \n",
    "\n",
    "from pathlib import Path \n",
    "\n",
    "pdf_root = r\"./log/simplePDF\"    # ~root/subdir/ ..data\n",
    "imPDF_root = r\"./log/ImagePDF\"   # ~root/subdir/ ..data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031680bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd70887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "project_root = Path(__file__).parent.parent\n",
    "file_md = r\"\"\n",
    "file_pdf = r\"\"\n",
    "\n",
    "\n",
    "file_md_im = r\"\"\n",
    "file_pdf_im = r\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15b7e3",
   "metadata": {},
   "source": [
    "### ÈÉ®ÁΩ≤  llama_deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2254e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
