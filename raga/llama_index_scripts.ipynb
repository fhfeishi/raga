{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5632732",
   "metadata": {},
   "source": [
    "### RAG  llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b415a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file-parser\n",
    "from typing import List, Dict, Any   \n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings \n",
    "from llama_index.core.node_parser import SentenceSplitter, TokenTextSplitter, MarkdownNodeParser \n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.extractors import TitleExtractor   # éœ€è¦æ¥å…¥llm\n",
    "\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# embedding\n",
    "embedding = HuggingFaceEmbedding(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "    device=\"cpu\",                 # å»ºè®®æ”¾é¡¶å±‚\n",
    "    cache_folder=r\"E:\\local_models\\huggingface\\cache\\hub\",\n",
    "    trust_remote_code=True,       # å»ºè®®æ”¾é¡¶å±‚\n",
    "    model_kwargs={\"local_files_only\": False},   # å…è®¸è”ç½‘ False\n",
    ")\n",
    "Settings.embed_model = embedding\n",
    "\n",
    "# full_split.md      figs_MetaDict.json  \n",
    "data_root = r\"../.log/SimplePDF\"\n",
    "mdfs: str = str(next(Path(data_root).rglob('full_split.md'), None))\n",
    "assert  Path(mdfs).exists()\n",
    "\n",
    "# å…ƒæ•°æ® ++\n",
    "# ä¿å­˜å›¾ç‰‡ä¿¡æ¯å­—æ®µçš„jsonæ–‡ä»¶åœ¨mdfsçš„åŒçº§ç›®å½•ä¸‹ æ–‡ä»¶å figs_MetaDict.json\n",
    "def load_jsf(mdp: Path) -> Dict[str, str | List]:\n",
    "    jsp = str(next(Path(mdp).parent.glob(\"figs_MetaDict.json\"),None))\n",
    "    if not jsp:\n",
    "        raise TypeError(\"jsp is NoneType\")\n",
    "    # assert jsp\n",
    "    \n",
    "    with open(jsp, \"r\", encoding='utf-8') as jf:\n",
    "        ims_metadata = json.load(jf)\n",
    "    return ims_metadata\n",
    "\n",
    "\"\"\" figs_metadict.json  \n",
    "{\n",
    "    \"im_abs\": [\n",
    "        \"æ‘˜è¦å›¾\",\n",
    "        \"path/to/im_abs\"\n",
    "    ],\n",
    "    \"lines_ims\": [                    \n",
    "        \"å›¾1ä¸ºæœ¬å®ç”¨æ–°å‹çš„çˆ†ç‚¸å›¾\",\n",
    "        \"å›¾2ä¸ºæœ¬å®ç”¨æ–°å‹çš„ä¾§é¢ç¤ºå›¾\",\n",
    "        ...\n",
    "    ],\n",
    "    \"annos_ims\": \"å›¾ä¸­ï¼š1ã€é©±åŠ¨æ¿ï¼›2ã€è½¬å­ç¼–ç å™¨èŠ¯ç‰‡ï¼›...\",\n",
    "    \"im_1\": [\n",
    "        \"å›¾1ä¸ºæœ¬å®ç”¨æ–°å‹çš„çˆ†ç‚¸å›¾\",\n",
    "        \"path/to/im_1\"\n",
    "    ],\n",
    "    \"im_2\": [\n",
    "        \"å›¾2ä¸ºæœ¬å®ç”¨æ–°å‹çš„ä¾§é¢ç¤ºå›¾\",\n",
    "        \"path/to/im_2\"\n",
    "    ],\n",
    "    ...\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# load_data\n",
    "documents = SimpleDirectoryReader(input_files=[mdfs]).load_data()\n",
    "# # figs_metadict  \n",
    "figs_dict = load_jsf(mdfs)   \n",
    "\n",
    "# spliter\n",
    "text_spliter = SentenceSplitter(chunk_size=700, chunk_overlap=100)\n",
    "\n",
    "# èŠ‚ç‚¹åå¤„ç†å™¨  Postprocessor        \n",
    "# ç›¸åº”åˆæˆå™¨    Response Synthesizer    # todo.\n",
    "from llama_index.core.postprocessor import KeywordNodePostprocessor, LongContextReorder #  \n",
    "# pipeline \n",
    "pipeline = IngestionPipeline(transformations=[text_spliter])\n",
    "\n",
    "# nodes\n",
    "nodes = pipeline.run(documents=documents)\n",
    "\n",
    "# ç»™æ¯ä¸ª node è®°å½• doc_id/figs_pathï¼Œåé¢å¥½å–å›¾ï¼Œå›¾çš„æè¿°è¯­ä¹Ÿæ˜¯éœ€è¦ä¸€åŒæå–å‡ºæ¥çš„ï¼Œå›¾ä¸­çš„æ ‡è®°æˆ–è®¸ä¹Ÿéœ€è¦å±•ç¤º/è¾“å‡ºå‡ºæ¥\n",
    "doc_id = Path(mdfs).parent.name\n",
    "for n in nodes:\n",
    "    n.metadata[\"doc_id\"] = doc_id\n",
    "    n.metadata[\"figs_path\"] = str(Path(mdfs).with_name(\"figs_MetaDict.json\"))\n",
    "\n",
    "\n",
    "# index\n",
    "nodes_idx = VectorStoreIndex(nodes=nodes)\n",
    "\n",
    "# 3) çº¯æ£€ç´¢ï¼šä¸èµ° LLMï¼Œåªå– SourceNodes\n",
    "retriever = nodes_idx.as_retriever(similarity_top_k=3)\n",
    "query = \"ä»‹ç»ä¸€ä¸‹è¿™æ˜¯ä»€ä¹ˆä¸“åˆ©\"\n",
    "source_nodes = retriever.retrieve(query)\n",
    "\n",
    "# 4) å…³è”å›¾ç‰‡ï¼ˆæœ€ç®€å•è§„åˆ™ï¼šchunk æ–‡æœ¬é‡Œæ‰¾â€œå›¾Nâ€ï¼‰\n",
    "import re\n",
    "def pick_figs_for_text(text: str, figs: Dict[str, Any], top_k:int=2):\n",
    "    out = []\n",
    "    nums = [int(m.group(1)) for m in re.finditer(r'å›¾\\s*(\\d+)', text)]\n",
    "    seen = set()\n",
    "    for n in nums:\n",
    "        key = f\"im_{n}\"\n",
    "        if key in figs and n not in seen:\n",
    "            cap, path = figs[key]\n",
    "            out.append({\"no\": n, \"caption\": cap, \"url\": path})\n",
    "            seen.add(n)\n",
    "            if len(out) >= top_k: break\n",
    "    # è¡¥ä¸€ä¸ªæ‘˜è¦å›¾å…œåº•\n",
    "    if len(out) == 0 and \"im_abs\" in figs:\n",
    "        cap, path = figs[\"im_abs\"]\n",
    "        out.append({\"no\": 0, \"caption\": cap, \"url\": path})\n",
    "    return out\n",
    "\n",
    "payload = []\n",
    "for sn in source_nodes:\n",
    "    figs = figs_dict  # å•æ–‡æ¡£å°±ç›´æ¥ç”¨ï¼›å¤šæ–‡æ¡£å¯æŒ‰ sn.node.metadata[\"doc_id\"] é€‰æ‹©\n",
    "    figs_pick = pick_figs_for_text(sn.node.get_text(), figs, top_k=2)\n",
    "    payload.append({\n",
    "        \"score\": sn.score,\n",
    "        \"text\": sn.node.get_text(),\n",
    "        \"figures\": figs_pick,\n",
    "        \"annos\": figs.get(\"annos_ims\", \"\")\n",
    "    })\n",
    "\n",
    "# æ‰“å°/è¿”å›ç»™å‰ç«¯\n",
    "for i, item in enumerate(payload, 1):\n",
    "    print(f\"\\n=== å‘½ä¸­ {i} (score={item['score']:.3f}) ===\")\n",
    "    print(item[\"text\"], \"...\")\n",
    "    if item[\"figures\"]:\n",
    "        print(\"ç›¸å…³å›¾ï¼š\", [f\"å›¾{f['no']}\" for f in item[\"figures\"]])\n",
    "    if item[\"annos\"]:\n",
    "        print(\"é™„å›¾æ ‡è®°ï¼š\", item[\"annos\"][:120], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483a2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ims-info-dict   txts-str \n",
    "\n",
    "# ims-info-dict.keys(): im_abs lines_ims annos_ims im_n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c45b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# agents.ipynb\n",
    "\"\"\"   \n",
    "#### AgentWorkflowçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ\n",
    "# AgentWorkflow å•ä¸ªæ™ºèƒ½ä½“ã€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å¤šä¸ªæ™ºèƒ½ä½“åä½œå®Œæˆä»»åŠ¡ï¼Œå¹¶åœ¨éœ€è¦æ—¶å°†æ§åˆ¶æƒäº’ç›¸ç§»äº¤\n",
    "# - ResearchAgent  : å®ƒå°†æœç´¢ç½‘ç»œä¸€æŸ¥æ‰¾ç»™å®šä¸»é¢˜çš„ä¿¡æ¯\n",
    "# - WriteAgent     : å°†ç”¨ResearchAgentæ£€ç´¢åˆ°çš„ä¿¡æ¯æ¥æ’°å†™æŠ¥å‘Š\n",
    "# - ReviewAgent    : å°†å®¡æŸ¥æŠ¥å‘Šå¹¶æä¾›åé¦ˆ\n",
    "## éœ€è¦ç”¨åˆ°çš„å·¥å…·\n",
    "# web_searchå·¥å…·ï¼Œ  Tavily\n",
    "# record_noteså·¥å…·ï¼Œå°†ç½‘ç»œæœç´¢é“å¾·ç ”ç©¶ä¿å­˜åˆ°çŠ¶æ€ä¸­ï¼ˆAgentWorkflowä½¿ç”¨ä¸€ä¸ªåä¸ºstateçš„Contextå˜é‡ï¼‰ï¼Œç„¶åå…¶ä»–å·¥å…·å°±å¯ä»¥ä½¿ç”¨å®ƒ\n",
    "# write_repotå·¥å…·ï¼Œä½¿ç”¨ResearchAgentæ£€ç´¢åˆ°çš„ä¿¡æ¯æ’°å†™æŠ¥å‘Š\n",
    "# review_reportå·¥å…·ï¼Œå®¡æŸ¥æŠ¥å‘Šå’Œæä¾›åé¦ˆ\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"   \n",
    "# HuggingFaceLLM ä¸æ”¯æŒå‡½æ•°è°ƒç”¨/å·¥å…·é€‰æ‹©   è®¸å¤šæœ¬åœ°å°æ¨¡å‹éƒ½ä¸æ”¯æŒå‡½æ•°è°ƒç”¨ã€å·¥å…·æ”¯æŒï¼Œ\n",
    "\n",
    "æƒ³ç”¨æœ¬åœ°/ç¦»çº¿æ¨¡å‹ï¼Œä½†åˆè¦å¤šæ™ºèƒ½ä½“ä¸å·¥å…·è°ƒç”¨ï¼Œæœ‰ä¸¤æ¡è·¯ï¼š\n",
    "  1. åœ¨æœ¬åœ°æ¨¡å‹ä¸Šå†å¥—ä¸€å±‚åŒ…è£…å™¨ï¼ˆ       -- ç®€å•æ–¹æ³•ï¼Œ \"æ™ºèƒ½ä½“\"  æ¨¡å‹è‡ªå·±å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·/å‡½æ•°ã€ç„¶åæœ¬åœ°æœºå™¨è°ƒç”¨å·¥å…·/å‡½æ•°\n",
    "- è·‘ä¸€ä¸ª OpenAI-å…¼å®¹ç½‘å…³ï¼ˆå¦‚ vLLM + OpenAI æ¥å£ã€LiteLLM ç­‰ï¼‰ï¼ŒæŠŠæœ¬åœ°æ¨¡å‹â€œæŒ‚æˆâ€ OpenAI-style APIï¼Œå†ç”¨ OpenAI å°è£…ï¼›\n",
    "  2. æ¨¡å‹åªè´Ÿè´£ç”Ÿæˆæ–‡æœ¬ï¼Œä¸è´Ÿè´£é€‰å·¥å…·   --å¤æ‚æ–¹æ³•\n",
    "- æ”¾å¼ƒâ€œç”±æ¨¡å‹è‡ªå·±å†³å®šä½•æ—¶è°ƒå·¥å…·â€ï¼Œæ”¹ä¸ºå·¥ä½œæµæ˜¾å¼ç¼–æ’ï¼šç”±ä½ åœ¨ Python ä¸­å†³å®šå…ˆæœâ†’å†è®°ç¬”è®°â†’å†å†™â†’å†å®¡ï¼ˆæ¨¡å‹åªè´Ÿè´£ç”Ÿæˆæ–‡æœ¬ï¼Œä¸è´Ÿè´£é€‰å·¥å…·ï¼‰ã€‚\n",
    "\"\"\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from llama_index.core.agent.workflow import AgentWorkflow \n",
    "from llama_index.core.workflow import Context \n",
    "from llama_index.core.agent.workflow import (\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    ")\n",
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent \n",
    "import os \n",
    "\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM \n",
    "llm = HuggingFaceLLM(\n",
    "    model_name     = r\"Qwen/Qwen3-1.7B\",\n",
    "    tokenizer_name = r\"Qwen/Qwen3-1.7B\",\n",
    "    context_window = 3900,  \n",
    "    max_new_tokens = 640,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 30, \"top_p\": 0.95},\n",
    "    device_map     ='cpu' \n",
    ")\n",
    "# HuggingFaceLLM ä¸æ”¯æŒå‡½æ•°è°ƒç”¨/å·¥å…·é€‰æ‹©\n",
    "\n",
    "tavily_tool = TavilyToolSpec(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "search_web = tavily_tool.to_tool_list()[0]\n",
    "\n",
    "# ---- å·¥å…·å‡½æ•°   \n",
    "async def record_notes(ctx: Context, notes: str, notes_title: str) -> str:\n",
    "    \"\"\" useful for recording notes on a gaven topic.\"\"\"\n",
    "    current_state = await ctx.store.get(\"state\")\n",
    "    if \"research_notes\" not in current_state:\n",
    "        current_state[\"research_notes\"] = {}\n",
    "    current_state[\"research_notes\"][notes_title] = notes\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    return \"Notes recorded.\"\n",
    "\n",
    "async def write_report(ctx:Context, report_content:str) -> str:\n",
    "    \"\"\" useful write a report on a gaven topic.\"\"\"\n",
    "    current_state = ctx.store.get(\"state\")\n",
    "    current_state[\"report_content\"] = report_content\n",
    "    await ctx.store.set(\"state\", current_state)\n",
    "    return \"Report written\"\n",
    "    \n",
    "async def review_report(ctx:Context, review:str) -> str:\n",
    "    \"\"\"useful for reviewing a report and providing feedbacks\"\"\"\n",
    "    current_state = ctx.store.get(\"state\")\n",
    "    current_state[\"review\"] = review\n",
    "    await ctx.store.set([\"state\"],current_state)\n",
    "    return \"Report reviewed\" \n",
    "\n",
    "# ------------- agent\n",
    "research_agent = FunctionAgent(\n",
    "    name=\"ResearchAgent\",\n",
    "    description=\"Useful for searching the web for information on a given topic and recording notes on the topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ResearchAgent that can search the web for information on a given topic and record notes on the topic. \"\n",
    "        \"Once notes are recorded and you are satisfied, you should hand off control to the WriteAgent to write a report on the topic.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[search_web, record_notes],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "write_agent = FunctionAgent(\n",
    "    name=\"WriteAgent\",\n",
    "    description=\"Useful for writing a report on a given topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the WriteAgent that can write a report on a given topic. \"\n",
    "        \"Your report should be in a markdown format. The content should be grounded in the research notes. \"\n",
    "        \"Once the report is written, you should get feedback at least once from the ReviewAgent.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[write_report],\n",
    "    can_handoff_to=[\"ReviewAgent\", \"ResearchAgent\"],\n",
    ")\n",
    "\n",
    "review_agent = FunctionAgent(\n",
    "    name=\"ReviewAgent\",\n",
    "    description=\"Useful for reviewing a report and providing feedback.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ReviewAgent that can review a report and provide feedback. \"\n",
    "        \"Your feedback should either approve the current report or request changes for the WriteAgent to implement.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[review_report],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "agent_workflow = AgentWorkflow(\n",
    "    agents=[research_agent, write_agent, review_agent],\n",
    "    root_agent=research_agent.name,\n",
    "    initial_state={\n",
    "        \"research_notes\": {},\n",
    "        \"report_content\": \"Not written yet.\",\n",
    "        \"review\": \"Review required.\",\n",
    "    },\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    handler = agent_workflow.run(user_msg=\"\"\"\n",
    "        Write me a report on the history of the web. Briefly describe the history \n",
    "        of the world wide web, including the development of the internet and the \n",
    "        development of the web, including 21st century developments.\n",
    "    \"\"\")\n",
    "    \n",
    "    current_agent = None \n",
    "    current_tool_calls = \"\" \n",
    "    async for event in handler.stream_events():\n",
    "        if (\n",
    "            hasattr(event, \"current_agent_name\")\n",
    "            and event.current_agent_name != current_agent\n",
    "        ):\n",
    "            current_agent = event.current_agent_name\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"ğŸ¤– Agent: {current_agent}\")\n",
    "            print(f\"{'='*50}\\n\")\n",
    "        elif isinstance(event, AgentOutput):\n",
    "            if event.response.content:\n",
    "                print(\"ğŸ“¤ Output:\", event.response.content)\n",
    "            if event.tool_calls:\n",
    "                print(\n",
    "                    \"ğŸ› ï¸  Planning to use tools:\",\n",
    "                    [call.tool_name for call in event.tool_calls],\n",
    "                )\n",
    "        elif isinstance(event, ToolCallResult):\n",
    "            print(f\"ğŸ”§ Tool Result ({event.tool_name}):\")\n",
    "            print(f\"  Arguments: {event.tool_kwargs}\")\n",
    "            print(f\"  Output: {event.tool_output}\")\n",
    "        elif isinstance(event, ToolCall):\n",
    "            print(f\"ğŸ”¨ Calling Tool: {event.tool_name}\")\n",
    "            print(f\"  With arguments: {event.tool_kwargs}\")\n",
    "\n",
    "\"\"\"   .py\n",
    "if __name__ == '__main__':\n",
    "    import asyncio \n",
    "    asyncio.run(main())\n",
    "\"\"\"\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ˜¾ç¤ºå·¥ä½œæµå®‰æ’ï¼Œ å› ä¸ºç°åœ¨æˆ‘çš„æœ¬åœ°hf-llmä¸æ”¯æŒå·¥å…·/å‡½æ•°è°ƒç”¨ï¼ˆæ— function-callingï¼‰  -- runs ok  \n",
    "# ### ç¼ºç‚¹ï¼š ä¸­é—´ä¿¡æ¯å¤ç”¨çš„ä»£ç é€»è¾‘ä¸å¥½å†™ï¼Œæ‰€ä»¥è¿˜æ˜¯ç”¨llama-indexï¼ˆContextï¼‰\n",
    "# æœ¬åœ°hf-llmåªç”Ÿæˆæ–‡æœ¬ï¼ˆé€šè¿‡æç¤ºè¯æ§åˆ¶ ç”Ÿæˆæ–‡æœ¬ è¿™ä¸ªè¡Œä¸ºï¼‰ï¼Œ\n",
    "# å…¶ä½™çš„æˆ‘æ¥\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os, json, re, textwrap, requests\n",
    "\n",
    "# 1) æœ¬åœ°/ç¦»çº¿ LLMï¼ˆä¸éœ€è¦å·¥å…·è°ƒç”¨åè®®ï¼‰\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name     = r\"Qwen/Qwen3-1.7B\",\n",
    "    tokenizer_name = r\"Qwen/Qwen3-1.7B\",\n",
    "    context_window = 3900,\n",
    "    max_new_tokens = 640,\n",
    "    generate_kwargs={\"temperature\": 0.5, \"top_k\": 30, \"top_p\": 0.95},\n",
    "    device_map     = \"cpu\",\n",
    ")\n",
    "\n",
    "# 2) Tavily æœç´¢ï¼ˆç›´æ¥ RESTï¼›ä¸ä¾èµ– LlamaIndex çš„ Toolï¼‰\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "def tavily_search(query: str, max_results: int = 6, depth: str = \"advanced\"):\n",
    "    \"\"\"æ˜¾å¼è°ƒç”¨ Tavily çš„ REST APIã€‚\"\"\"\n",
    "    url = \"https://api.tavily.com/search\"\n",
    "    payload = {\n",
    "        \"api_key\": TAVILY_API_KEY,\n",
    "        \"query\": query,\n",
    "        \"search_depth\": depth,           # \"basic\" / \"advanced\"\n",
    "        \"include_images\": False,\n",
    "        \"include_answer\": False,\n",
    "        \"max_results\": max_results,\n",
    "    }\n",
    "    r = requests.post(url, json=payload, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    # æœŸæœ› data[\"results\"] æ˜¯ [{title, url, content, score?}, ...]\n",
    "    return data.get(\"results\", [])\n",
    "\n",
    "def _trim(s: str, n=8000):\n",
    "    return s if len(s) <= n else (s[:n] + \" ...[truncated]\")\n",
    "\n",
    "# --------------------- æ˜¾å¼â€œå·¥ä½œæµâ€æ­¥éª¤ ---------------------\n",
    "\n",
    "def step_research(topic: str) -> dict:\n",
    "    \"\"\"Step-1: æœç´¢ + ç”Ÿæˆç»“æ„åŒ–ç¬”è®°ï¼ˆæ˜¾å¼è°ƒç”¨ Tavily ä¸æœ¬åœ°LLMï¼‰\"\"\"\n",
    "    results = tavily_search(topic, max_results=6, depth=\"advanced\")\n",
    "    sources_md = \"\\n\".join(\n",
    "        f\"- [{it.get('title','(no title)')}]({it.get('url','')}) â€” {it.get('content','')[:240].replace('\\n', ' ')}\"\n",
    "        for it in results\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "ä½ æ˜¯ç ”ç©¶åŠ©ç†ã€‚åŸºäºä¸‹åˆ—æ£€ç´¢åˆ°çš„èµ„æ–™ï¼Œä¸ºâ€œ{topic}â€ç”Ÿæˆä¸è¶…è¿‡ 10 æ¡çš„è¦ç‚¹å¼ç ”ç©¶ç¬”è®°ï¼ˆMarkdownï¼‰ã€‚\n",
    "è¦æ±‚ï¼š\n",
    "- è¦†ç›–å…³é”®æ—¶é—´çº¿/é‡Œç¨‹ç¢‘/æ ¸å¿ƒäººç‰©æˆ–æœºæ„\n",
    "- çªå‡º 21 ä¸–çºªçš„å‘å±•ï¼ˆè‹¥ç›¸å…³ï¼‰\n",
    "- å°½é‡å¼•ç”¨æ¥æºï¼ˆä»¥ [ç¼–å·] å½¢å¼å¯¹ç…§ä¸‹æ–¹â€œèµ„æ–™åˆ—è¡¨â€åºå·ï¼‰\n",
    "\n",
    "èµ„æ–™åˆ—è¡¨ï¼ˆæŒ‰é¡ºåºæ ‡å·ï¼‰ï¼š\n",
    "{sources_md}\n",
    "\n",
    "è¯·è¾“å‡ºï¼š\n",
    "### ç¬”è®°\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n",
    "### å¼•ç”¨æ¥æº\n",
    "- [1] æ ‡é¢˜ï¼ˆé“¾æ¥ï¼‰\n",
    "- [2] ...\n",
    "\"\"\"\n",
    "    notes = llm.complete(prompt).text\n",
    "    state = {\n",
    "        \"topic\": topic,\n",
    "        \"search_results\": results,\n",
    "        \"notes_md\": notes,\n",
    "        \"sources_md\": sources_md,\n",
    "    }\n",
    "    return state\n",
    "\n",
    "def step_write_report(state: dict) -> dict:\n",
    "    \"\"\"Step-2: å†™æŠ¥å‘Šï¼ˆæ˜¾å¼æŠŠä¸Šä¸€æ­¥çš„ç¬”è®°ä¼ å…¥ LLMï¼‰\"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    notes_md = state[\"notes_md\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "ä½ æ˜¯ä¸€åæŠ€æœ¯å†™ä½œè€…ã€‚è¯·åŸºäºä¸‹æ–¹â€œç ”ç©¶ç¬”è®°â€ä¸ºä¸»é¢˜â€œ{topic}â€æ’°å†™ä¸€ç¯‡**ç»“æ„åŒ– Markdown æŠ¥å‘Š**ã€‚\n",
    "è¦æ±‚ï¼š\n",
    "- ç»“æ„ç¤ºä¾‹ï¼š# æ¦‚è§ˆ / ## æ—©æœŸå‘å±• / ## 1990s / ## 2000s / ## 2010s-2020s / ## å‚è€ƒèµ„æ–™\n",
    "- å†…å®¹å¿…é¡»**ç´§å¯†ä¾èµ–**ç ”ç©¶ç¬”è®°ï¼Œä¸è¦ç¼–é€ \n",
    "- è¯­è¨€ç®€æ´ï¼Œæ®µè½çŸ­å°\n",
    "\n",
    "--- ç ”ç©¶ç¬”è®° ---\n",
    "{notes_md}\n",
    "\"\"\"\n",
    "    report_md = llm.complete(prompt).text\n",
    "    state[\"report_md\"] = report_md\n",
    "    return state\n",
    "\n",
    "def _extract_json_block(text: str) -> dict:\n",
    "    \"\"\"ä»æ¨¡å‹è¾“å‡ºä¸­å°½é‡æå– JSONï¼ˆç¨³å¥è§£æï¼‰\"\"\"\n",
    "    # å…ˆæ‰¾ ```json ... ``` åŒ…è£¹\n",
    "    m = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", text, flags=re.S)\n",
    "    if not m:\n",
    "        # é€€åŒ–ï¼šæ‰¾ç¬¬ä¸€ä¸ª { ... } å—\n",
    "        m = re.search(r\"(\\{.*\\})\", text, flags=re.S)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(m.group(1))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def step_review(state: dict, strict: bool = False) -> dict:\n",
    "    \"\"\"Step-3: å®¡ç¨¿ï¼ˆè¾“å‡º JSONï¼šapproved/changesï¼‰\"\"\"\n",
    "    report_md = state[\"report_md\"]\n",
    "    prompt = f\"\"\"\n",
    "ä½ æ˜¯å®¡ç¨¿äººã€‚è¯·ä»…ä»¥ JSON æ–¹å¼ç»™å‡ºå®¡ç¨¿ç»“è®ºã€‚\n",
    "è§„åˆ™ï¼š\n",
    "- å­—æ®µï¼šapproved (bool), summary (string), changes (string[])\n",
    "- è‹¥ approved=falseï¼Œè¯·ç»™å‡º 3-6 æ¡å…·ä½“ä¿®æ”¹å»ºè®®\n",
    "- è¾“å‡ºå¿…é¡»æ”¾åœ¨ä¸€ä¸ª ```json å—ä¸­ï¼Œä¸è¦å‡ºç°å¤šä½™æ–‡å­—\n",
    "\n",
    "--- å¾…å®¡æŠ¥å‘Š ---\n",
    "{_trim(report_md, 7000)}\n",
    "\"\"\"\n",
    "    review_raw = llm.complete(prompt).text\n",
    "    parsed = _extract_json_block(review_raw)\n",
    "    # å®¹é”™ï¼šé»˜è®¤é€šè¿‡\n",
    "    approved = bool(parsed.get(\"approved\", True))\n",
    "    changes = parsed.get(\"changes\", [])\n",
    "    summary = parsed.get(\"summary\", \"OK\")\n",
    "\n",
    "    state[\"review\"] = {\n",
    "        \"raw\": review_raw,\n",
    "        \"parsed\": parsed,\n",
    "        \"approved\": approved,\n",
    "        \"changes\": changes,\n",
    "        \"summary\": summary,\n",
    "    }\n",
    "    return state\n",
    "\n",
    "def step_revise_if_needed(state: dict, max_rounds: int = 1) -> dict:\n",
    "    \"\"\"å¯é€‰ï¼šæ ¹æ®å®¡ç¨¿æ„è§è¿›è¡Œ 0~N è½®ä¿®è®¢\"\"\"\n",
    "    rounds = 0\n",
    "    while rounds < max_rounds and not state[\"review\"][\"approved\"]:\n",
    "        changes = state[\"review\"][\"changes\"]\n",
    "        report_md = state[\"report_md\"]\n",
    "        topic = state[\"topic\"]\n",
    "        notes_md = state[\"notes_md\"]\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "æ ¹æ®ä»¥ä¸‹å®¡ç¨¿æ„è§ä¿®è®¢æŠ¥å‘Šã€Š{topic}ã€‹ã€‚å¿…é¡»éµå¾ªå®¡ç¨¿æ¡ç›®é€æ¡ä¿®æ”¹ï¼š\n",
    "- å®¡ç¨¿æ„è§ï¼š\n",
    "{json.dumps(changes, ensure_ascii=False, indent=2)}\n",
    "\n",
    "é™åˆ¶ï¼š\n",
    "- ä»éœ€ä¸¥æ ¼ä¾èµ–â€œç ”ç©¶ç¬”è®°â€ï¼Œä¸è¦ç¼–é€ \n",
    "- ä¿æŒ Markdown ç»“æ„æ¸…æ™°\n",
    "\n",
    "--- ç ”ç©¶ç¬”è®° ---\n",
    "{notes_md}\n",
    "\n",
    "--- æ—§ç‰ˆæŠ¥å‘Š ---\n",
    "{_trim(report_md, 7000)}\n",
    "\"\"\"\n",
    "        new_report = llm.complete(prompt).text\n",
    "        state[\"report_md\"] = new_report\n",
    "        # é‡æ–°å®¡ç¨¿\n",
    "        state = step_review(state)\n",
    "        rounds += 1\n",
    "    return state\n",
    "\n",
    "# --------------------- é¡¶å±‚ orchestrator ---------------------\n",
    "\n",
    "def run_explicit_workflow(user_request: str, revise_rounds: int = 1) -> dict:\n",
    "    # 1) ç ”ç©¶\n",
    "    state = step_research(user_request)\n",
    "    print(\"âœ… Research done.\")\n",
    "\n",
    "    # 2) å†™ä½œ\n",
    "    state = step_write_report(state)\n",
    "    print(\"âœ… Draft written.\")\n",
    "\n",
    "    # 3) å®¡ç¨¿\n",
    "    state = step_review(state)\n",
    "    print(f\"âœ… Review: approved={state['review']['approved']}\")\n",
    "\n",
    "    # 4) éœ€è¦çš„è¯ï¼Œä¿®è®¢è‹¥å¹²è½®\n",
    "    state = step_revise_if_needed(state, max_rounds=revise_rounds)\n",
    "    print(f\"âœ… Final approved={state['review']['approved']}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "# --------------------- è¿è¡Œç¤ºä¾‹ ---------------------\n",
    "if __name__ == \"__main__\":\n",
    "    topic = \"History of the World Wide Web and key 21st-century developments\"\n",
    "    final_state = run_explicit_workflow(topic, revise_rounds=1)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"# æœ€ç»ˆæŠ¥å‘Šï¼ˆæˆªæ–­å±•ç¤ºï¼‰\\n\")\n",
    "    print(_trim(final_state[\"report_md\"], 4000))\n",
    "    print(\"\\n# å®¡ç¨¿è§£æï¼š\", final_state[\"review\"][\"parsed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¨ LlamaIndex çš„ Workflowï¼ˆä»æ˜¯æ˜¾å¼è·¯å¾„ï¼Œä¸è®©æ¨¡å‹æŒ‘å·¥å…·ï¼‰\n",
    "# explicit_workflow_llamaindex.py  â€”â€” æ˜¾å¼ç¼–æ’ï¼Œæ—  function-calling\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os, json, re, requests\n",
    "from typing import Union\n",
    "\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.workflow import (\n",
    "    Workflow, StartEvent, StopEvent, step, Event\n",
    ")\n",
    "\n",
    "# ================== åŸºç¡€ç»„ä»¶ ==================\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name     = r\"Qwen/Qwen3-1.7B\",\n",
    "    tokenizer_name = r\"Qwen/Qwen3-1.7B\",\n",
    "    context_window = 3900,\n",
    "    max_new_tokens = 640,\n",
    "    generate_kwargs={\"temperature\": 0.5, \"top_k\": 30, \"top_p\": 0.95},\n",
    "    device_map     = \"cpu\",\n",
    ")\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "def tavily_search(query: str, max_results: int = 6):\n",
    "    url = \"https://api.tavily.com/search\"\n",
    "    payload = {\n",
    "        \"api_key\": TAVILY_API_KEY,\n",
    "        \"query\": query,\n",
    "        \"search_depth\": \"advanced\",\n",
    "        \"max_results\": max_results\n",
    "    }\n",
    "    resp = requests.post(url, json=payload, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json().get(\"results\", [])\n",
    "\n",
    "def _extract_json_block(text: str) -> dict:\n",
    "    m = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", text, flags=re.S) or re.search(r\"(\\{.*\\})\", text, flags=re.S)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(m.group(1))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# ================== äº‹ä»¶ç±»å‹ï¼ˆæ˜¾å¼å®šä¹‰ï¼‰ ==================\n",
    "class ResearchDone(Event):\n",
    "    topic: str\n",
    "    sources_md: str\n",
    "    notes_md: str\n",
    "\n",
    "class DraftWritten(Event):\n",
    "    topic: str\n",
    "    notes_md: str\n",
    "    report_md: str\n",
    "\n",
    "class ReviewApproved(Event):\n",
    "    topic: str\n",
    "    notes_md: str\n",
    "    report_md: str\n",
    "    review: dict  # {\"approved\": True, \"summary\": \"...\", \"changes\": []}\n",
    "\n",
    "class ReviewChangesNeeded(Event):\n",
    "    topic: str\n",
    "    notes_md: str\n",
    "    report_md: str\n",
    "    review: dict  # {\"approved\": False, \"summary\": \"...\", \"changes\": [...]}\n",
    "\n",
    "# ================== Workflow & Steps ==================\n",
    "class wf(Workflow):\n",
    "    # å› ä¸ºæ˜¯ä»å‰å¾€åï¼Œå•çº¿ï¼Œ æ‰€ä»¥ä¸ç”¨Contextä¹Ÿå¯ä»¥\n",
    "    @step\n",
    "    def research(ev: StartEvent) -> ResearchDone:\n",
    "        topic = ev.input[\"topic\"]\n",
    "        results = tavily_search(topic, max_results=6)\n",
    "        sources_md = \"\\n\".join(\n",
    "            f\"- [{it.get('title','(no title)')}]({it.get('url','')}) â€” {it.get('content','')[:240].replace('\\n',' ')}\"\n",
    "            for it in results\n",
    "        )\n",
    "        prompt = f\"è¯·åŸºäºä¸‹åˆ—èµ„æ–™ä¸ºâ€œ{topic}â€ç”Ÿæˆ 6-10 æ¡è¦ç‚¹å¼ Markdown ç¬”è®°ï¼š\\n{sources_md}\"\n",
    "        notes_md = llm.complete(prompt).text\n",
    "        return ResearchDone(topic=topic, sources_md=sources_md, notes_md=notes_md)\n",
    "\n",
    "    @step\n",
    "    def write(ev: ResearchDone) -> DraftWritten:\n",
    "        topic, notes_md = ev.topic, ev.notes_md\n",
    "        prompt = f\"åŸºäºç ”ç©¶ç¬”è®°ä¸ºâ€œ{topic}â€å†™ä¸€ç¯‡ç»“æ„åŒ– Markdown æŠ¥å‘Šï¼š\\n{notes_md}\"\n",
    "        report_md = llm.complete(prompt).text\n",
    "        return DraftWritten(topic=topic, notes_md=notes_md, report_md=report_md)\n",
    "\n",
    "    @step\n",
    "    def review(ev: DraftWritten) -> Union[ReviewApproved, ReviewChangesNeeded]:\n",
    "        report_md = ev.report_md\n",
    "        prompt = f\"\"\"ä½ æ˜¯å®¡ç¨¿äººï¼Œä»…ä»¥ JSON å›ç­”ï¼š{{\"approved\": true/false, \"summary\": \"...\", \"changes\": [\"...\"]}}ã€‚\n",
    "    æŠ¥å‘Šï¼š\n",
    "    {report_md}\n",
    "    \"\"\"\n",
    "        parsed = _extract_json_block(llm.complete(prompt).text)\n",
    "        if not parsed:\n",
    "            parsed = {\"approved\": True, \"summary\": \"OK\", \"changes\": []}\n",
    "\n",
    "        if bool(parsed.get(\"approved\", True)):\n",
    "            return ReviewApproved(\n",
    "                topic=ev.topic, notes_md=ev.notes_md, report_md=report_md, review=parsed\n",
    "            )\n",
    "        else:\n",
    "            return ReviewChangesNeeded(\n",
    "                topic=ev.topic, notes_md=ev.notes_md, report_md=report_md, review=parsed\n",
    "            )\n",
    "\n",
    "    @step\n",
    "    def revise(ev: ReviewChangesNeeded) -> DraftWritten:\n",
    "        \"\"\"æŒ‰å®¡ç¨¿æ„è§ä¿®è®¢ä¸€è½®åï¼Œå›åˆ° reviewã€‚\"\"\"\n",
    "        changes = ev.review.get(\"changes\", [])\n",
    "        prompt = (\n",
    "            \"æ ¹æ®ä»¥ä¸‹å®¡ç¨¿æ„è§ä¿®è®¢æŠ¥å‘Šï¼ˆä¿æŒ Markdown ç»“æ„ï¼Œé€æ¡è½å®ï¼‰ï¼š\\n\"\n",
    "            f\"{json.dumps(changes, ensure_ascii=False, indent=2)}\\n\"\n",
    "            \"---\\næ—§ç‰ˆï¼š\\n\"\n",
    "            f\"{ev.report_md}\"\n",
    "        )\n",
    "        new_report = llm.complete(prompt).text\n",
    "        return DraftWritten(topic=ev.topic, notes_md=ev.notes_md, report_md=new_report)\n",
    "\n",
    "    @step\n",
    "    def end(ev: ReviewApproved) -> StopEvent:\n",
    "        \"\"\"ç»ˆæ­¢ï¼šè¿”å›æœ€ç»ˆæŠ¥å‘Šä¸å®¡ç¨¿ç»“æœã€‚\"\"\"\n",
    "        return StopEvent(result={\"report_md\": ev.report_md, \"review\": ev.review})\n",
    "\n",
    "\n",
    "# =============== è¿è¡Œä¸æ‰“å° ===============\n",
    "handler = wf.run(input={\"topic\": \"History of the World Wide Web and 21st-century developments\"})\n",
    "\n",
    "# å¯é€‰ï¼šæ‰“å°äº‹ä»¶æµ\n",
    "for ev in handler.stream_events():\n",
    "    name = type(ev).__name__\n",
    "    payload = getattr(ev, \"result\", None)\n",
    "    if payload:\n",
    "        print(f\"[{name}] result keys: {list(payload) if isinstance(payload, dict) else str(payload)[:60]}\")\n",
    "    else:\n",
    "        print(f\"[{name}]\")\n",
    "\n",
    "final = handler.get()  # StopEvent.result\n",
    "print(\"\\n=== FINAL REPORT (snippet) ===\\n\")\n",
    "print(final[\"report_md\"][:2000])\n",
    "print(\"\\n=== REVIEW ===\\n\", json.dumps(final[\"review\"], ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea779dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file \n",
    "\n",
    "from pathlib import Path \n",
    "\n",
    "pdf_root = r\"./log/simplePDF\"    # ~root/subdir/ ..data\n",
    "imPDF_root = r\"./log/ImagePDF\"   # ~root/subdir/ ..data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031680bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd70887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "project_root = Path(__file__).parent.parent\n",
    "file_md = r\"\"\n",
    "file_pdf = r\"\"\n",
    "\n",
    "\n",
    "file_md_im = r\"\"\n",
    "file_pdf_im = r\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15b7e3",
   "metadata": {},
   "source": [
    "### éƒ¨ç½²  llama_deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2254e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
